{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scientific Workflow with HSSM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> <img src=\"./images/HSSM_logo.png\"> </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to the scientific workflow tutorial. This tutorial starts with a basic experimental dataset and we will inch from a very simple HSSM model iteratively toward a model that captures many of the main patterns we can identify in our dataset.\n",
    "\n",
    "Along the way we try to achieve the following balance:\n",
    "\n",
    "1. Illustrate how HSSM can be used for real scientific workflows. HSSM helps us with model building, running the stats, and reporting results.\n",
    "2. Allow this tutorial to be used as a **first** look into HSSM, shirking conceptually advanced features that are discused in the many dedicated tutorials you can find on the [documentation](https://lnccbrown.github.io/HSSM/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Colab Instructions\n",
    "\n",
    "If you would like to run this tutorial on Google colab, please click this [link](https://colab.research.google.com/github/lnccbrown/HSSM/blob/drop-more-notebooks-from-execute/carney_workshop/discovery_journey.ipynb). \n",
    "\n",
    "Once you are *in the colab*:\n",
    "\n",
    "1. Follow the **installation instructions below**  (uncomment the respective code)\n",
    "2.  **restart your runtime**. \n",
    "\n",
    "**NOTE**:\n",
    "\n",
    "You may want to *switch your runtime* to have a GPU or TPU. To do so, go to *Runtime* > *Change runtime type* and select the desired hardware accelerator.\n",
    "Note that if you switch your runtime you have to follow the installation instructions again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Install hssm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If running this on Colab, please uncomment the next line\n",
    "# !pip install hssm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Download tutorial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Data Files\n",
    "# !wget -P  data/carney_workshop_2025_data/ https://raw.githubusercontent.com/lnccbrown/HSSM/drop-more-notebooks-from-execute/carney_workshop/data/carney_workshop_2025_data/carney_workshop_2025_full.parquet\n",
    "# !wget -P  data/carney_workshop_2025_data/ https://raw.githubusercontent.com/lnccbrown/HSSM/drop-more-notebooks-from-execute/carney_workshop/data/carney_workshop_2025_data/carney_workshop_2025_modeling.parquet\n",
    "# !wget -P  data/carney_workshop_2025_data/ https://raw.githubusercontent.com/lnccbrown/HSSM/drop-more-notebooks-from-execute/carney_workshop/data/carney_workshop_2025_data/carney_workshop_2025_parameters.pkl\n",
    "\n",
    "# # Presampled traces\n",
    "# !wget -P  idata/basic_ddm/ https://raw.githubusercontent.com/lnccbrown/HSSM/drop-more-notebooks-from-execute/carney_workshop/idata/basic_ddm/traces.nc\n",
    "# !wget -P  idata/ddm_hier/ https://raw.githubusercontent.com/lnccbrown/HSSM/drop-more-notebooks-from-execute/carney_workshop/idata/ddm_hier/traces.nc\n",
    "# !wget -P  idata/angle_hier/ https://raw.githubusercontent.com/lnccbrown/HSSM/drop-more-notebooks-from-execute/carney_workshop/idata/angle_hier/traces.nc\n",
    "# !wget -P  idata/angle_hier_v2/ https://raw.githubusercontent.com/lnccbrown/HSSM/drop-more-notebooks-from-execute/carney_workshop/idata/angle_hier_v2/traces.nc\n",
    "# !wget -P  idata/angle_hier_v3/ https://raw.githubusercontent.com/lnccbrown/HSSM/drop-more-notebooks-from-execute/carney_workshop/idata/angle_hier_v3/traces.nc\n",
    "# !wget -P  idata/angle_hier_v4/ https://raw.githubusercontent.com/lnccbrown/HSSM/drop-more-notebooks-from-execute/carney_workshop/idata/angle_hier_v4/traces.nc\n",
    "# !wget -P  idata/angle_v5/ https://raw.githubusercontent.com/lnccbrown/HSSM/drop-more-notebooks-from-execute/carney_workshop/idata/angle_v5/traces.nc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start of Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hssm\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import arviz as az\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load workshop data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(filename_base: str,\n",
    "              folder: str = \"data\") -> tuple[pd.DataFrame, pd.DataFrame, dict]:\n",
    "    \"\"\"Load saved simulation data and parameters from files.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    filename_base : str\n",
    "        Base filename used when saving files\n",
    "    folder : str, optional\n",
    "        Folder containing saved files, by default \"data\"\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple[pd.DataFrame, pd.DataFrame, dict]\n",
    "        Contains:\n",
    "        - DataFrame with modeling data\n",
    "        - DataFrame with full data  \n",
    "        - Dict containing group and subject parameters\n",
    "    \"\"\"\n",
    "    df_modeling = pd.read_parquet(f\"{folder}/{filename_base}_modeling.parquet\")\n",
    "    return df_modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "workshop_data  = load_data(filename_base = \"carney_workshop_2025\",\n",
    "                           folder = \"data/carney_workshop_2025_data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Plotting Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "\n",
    "def plot_rt_by_choice(df: pd.DataFrame,\n",
    "                      categorical_column: str | None = None,\n",
    "                      colors: dict[str, str] | dict[int, str] | None = None,\n",
    "                      ax: plt.Axes | None = None):\n",
    "    if categorical_column is None:\n",
    "        ax.hist(df['rt'] * df['response'],\n",
    "                bins = np.linspace(-5,5, 50), \n",
    "                # label=f'Condition {cond}', \n",
    "                histtype='step',\n",
    "                density = True,\n",
    "                color='tab:blue')\n",
    "    else:\n",
    "        for cond in df[categorical_column].unique():\n",
    "            df_cond = df[df[categorical_column] == cond]\n",
    "            ax.hist(df_cond['rt'] * df_cond['response'],\n",
    "                    bins = np.linspace(-5,5, 50), \n",
    "                    label=f'Condition {cond}', \n",
    "                    histtype='step',\n",
    "                    density = True,\n",
    "                    color=colors[cond])\n",
    "        ax.set_xlabel('RT * Choice')\n",
    "        ax.set_ylabel('Density')\n",
    "    return ax\n",
    "        \n",
    "def inset_bar_plot(df: pd.DataFrame, \n",
    "                   categorical_column: str,\n",
    "                   response_options: list[int],\n",
    "                   colors: dict[str, str] | dict[int, str] | None = None,\n",
    "                   ax: plt.Axes | None = None):\n",
    "    \n",
    "    axins = inset_axes(ax, \n",
    "                       width=\"35%\",\n",
    "                       height=\"35%\",\n",
    "                       loc='upper left',\n",
    "                       borderpad=2.75)\n",
    "    bar_width = 0.55\n",
    "    for j, resp in enumerate(response_options):\n",
    "        for k, cond in enumerate(df[categorical_column].unique()):\n",
    "            k_displace = -1 if k == 0 else 1\n",
    "            df_cond = df[df[categorical_column] == cond]\n",
    "            prop = (df_cond[df_cond.response == resp].shape[0] / len(df_cond))\n",
    "            axins.bar((resp + ((bar_width / 2) * k_displace)), \n",
    "                        prop,\n",
    "                        width=bar_width,\n",
    "                        fill = False,\n",
    "                        edgecolor=colors[cond],\n",
    "                        label=f'Response {resp}')\n",
    "    axins.set_xticks(response_options)\n",
    "    axins.set_ylim(0, 1)\n",
    "    axins.set_yticks([0.0, 0.5, 1])\n",
    "    axins.set_title('choice proportion / option', fontsize=8)\n",
    "    axins.tick_params(axis='both', which='major', labelsize=7)\n",
    "    axins.set_xlabel('')\n",
    "    axins.set_ylabel('')\n",
    "    return ax\n",
    "\n",
    "def inset_bar_plot_vertical(df: pd.DataFrame,\n",
    "                            categorical_column: str,\n",
    "                            response_options: list[int],\n",
    "                            colors: dict[str, str] | dict[int, str] | None = None,\n",
    "                            ax: plt.Axes | None = None):\n",
    "    \n",
    "    axins = inset_axes(ax,\n",
    "                       width=\"35%\",\n",
    "                       height=\"35%\",\n",
    "                       loc='upper left',\n",
    "                       borderpad=2.25)\n",
    "    bar_width = 0.55\n",
    "    for j, resp in enumerate(response_options):\n",
    "        # k_displace_dict = {0:}\n",
    "        for k, cond in enumerate(df[categorical_column].unique()):\n",
    "            k_displace = -1 if k == 0 else 1\n",
    "            df_cond = df[df[categorical_column] == cond]\n",
    "            rt_mean = (df_cond[df_cond.response == resp]).rt.mean()\n",
    "            axins.barh((resp + ((bar_width / 2) * k_displace)), \n",
    "                       rt_mean,\n",
    "                       height=bar_width,\n",
    "                       fill = False,\n",
    "                       edgecolor=colors[cond],\n",
    "                       label=f'Response {resp}')\n",
    "\n",
    "    axins.set_yticks(response_options)\n",
    "    axins.set_xticks([0.0, 1., 2.])\n",
    "    axins.set_title('rt-mean by choice option', fontsize=8)\n",
    "    axins.tick_params(axis='both', which='major', labelsize=7)\n",
    "    axins.set_xlabel('')\n",
    "    axins.set_ylabel('')\n",
    "    return ax\n",
    "\n",
    "def plot_rt_hists(df: pd.DataFrame,\n",
    "                  by_participant: bool = True,\n",
    "                  split_by_column: str | None = None,\n",
    "                  inset_plot: str | None = \"choice proportion\",\n",
    "                  cols: int = 5):\n",
    "    if split_by_column is not None:\n",
    "        colors = {cond: color for cond, color in zip(df[split_by_column].unique(), \n",
    "                            ['tab:blue', 'tab:orange', 'tab:green', 'tab:red', 'tab:purple'])}\n",
    "    else:\n",
    "        colors = None\n",
    "\n",
    "    if by_participant:\n",
    "        # Get unique participant IDs and costly_fail_conditions\n",
    "        participants = df['participant_id'].unique()\n",
    "\n",
    "        # Set up subplot grid (adjust cols as needed)\n",
    "        rows = (len(participants) + cols - 1) // cols\n",
    "        fig, axes = plt.subplots(rows, cols, \n",
    "                                 figsize=(cols*4, rows*3), \n",
    "                                 sharey=True, sharex=True)\n",
    "        axes = axes.flatten()\n",
    "        for i, pid in enumerate(participants):\n",
    "            ax = axes[i]\n",
    "            df_part = df[df['participant_id'] == pid]\n",
    "            ax = plot_rt_by_choice(df_part,\n",
    "                                   split_by_column,\n",
    "                                   colors,\n",
    "                                   ax)\n",
    "            \n",
    "            # Take care of inset plots\n",
    "            if inset_plot == \"choice_proportion\":\n",
    "                ax = inset_bar_plot(df_part, \n",
    "                                    split_by_column,\n",
    "                                    df['response'].unique(),\n",
    "                                    colors,\n",
    "                                    ax)\n",
    "            elif inset_plot == \"rt_mean\":\n",
    "                ax = inset_bar_plot_vertical(df_part, \n",
    "                                             split_by_column,\n",
    "                                             df['response'].unique(),\n",
    "                                             colors,\n",
    "                                             ax)\n",
    "            if i == 0:\n",
    "                ax.legend(title=split_by_column, loc='best', fontsize='small')\n",
    "\n",
    "        # Hide unused axes\n",
    "        for j in range(i+1, len(axes)):\n",
    "            axes[j].set_visible(False)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.suptitle('RT, Split by Costly Fail Condition and Participant', y=1.02)\n",
    "        plt.show()\n",
    "    else:\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(4, 3))\n",
    "        ax = plot_rt_by_choice(df,\n",
    "                               split_by_column,\n",
    "                               colors,\n",
    "                               ax)\n",
    "\n",
    "        # Take care of inset plots\n",
    "        if inset_plot == \"choice_proportion\":\n",
    "            ax = inset_bar_plot(df,\n",
    "                                split_by_column,\n",
    "                                df['response'].unique(),\n",
    "                                colors,\n",
    "                                ax)\n",
    "        elif inset_plot == \"rt_mean\":\n",
    "            ax = inset_bar_plot_vertical(df,\n",
    "                                         split_by_column,\n",
    "                                         df['response'].unique(),\n",
    "                                         colors,\n",
    "                                         ax)\n",
    "        \n",
    "        ax.legend(title=split_by_column, loc='best', fontsize='small')\n",
    "        plt.tight_layout()\n",
    "        plt.suptitle('RT by Trial, Split by Costly Fail Condition', y=1.02)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "\n",
    "<center> <img src=\"images/Experiment.png\" height=300 width=700> </center>\n",
    "\n",
    "\n",
    "Now that we are done preparing the setup, let's get to the meat of it! The picture above gives us a bit of an idea, where the dataset that we are going to work with below comes from (alert: the backstory may or may not be real). \n",
    "\n",
    "**20** subjects, performed **250** trials each of a basic *Random dot motion* task. The task seemingly had two important manipulations. \n",
    "\n",
    "1. A **costly fail** condition, in which subjects get punished for mistakes.\n",
    "2. A trial by trail manipulation of **difficulty** (in the **Random dot motion** task, this refers to degree of coherence with which the dots move in a particular direction)\n",
    "\n",
    "Let's take a look at the actual dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workshop_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding a few columns\n",
    "\n",
    "As part of prep work for plotting etc. we will add a few columns here. These will be motivated later (close your eyes :))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary version of difficulty\n",
    "workshop_data['bin_difficulty'] = workshop_data['continuous_difficulty'].apply(lambda x: 'high' if x > 0 else 'low')\n",
    "\n",
    "# I want a a ordinal variable that is composed of 5 quantile levels of difficulty\n",
    "workshop_data['quantile_difficulty'] = pd.qcut(workshop_data['continuous_difficulty'],\n",
    "                                                             3, labels = ['-1', '0', '1'])\n",
    "\n",
    "workshop_data['quantile_difficulty_binary'] = pd.qcut(workshop_data['continuous_difficulty'],\n",
    "                                                             2, labels = ['-1', '1'])\n",
    "\n",
    "# Slightly\n",
    "workshop_data['response_l1_plotting'] = workshop_data['response_l1'].apply(lambda x: str(-1) if x == -1 else str(1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Most basic reaction time plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rt_hists(workshop_data, \n",
    "              by_participant = False, \n",
    "              split_by_column = None,\n",
    "              inset_plot = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far so good. Looking at the global reaction time pattern, it does seem commensurate with what we might expect out of basic Sequential Sampling Model (SSM). The basic DDM might be a good start here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Model: DDM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center> <img src=\"images/DDM_with_params_pic.png\" height=\"500\" width=\"500\"> </center>\n",
    "\n",
    "The picture above illustrates the basic [Drift Diffusion Model](https://pmc.ncbi.nlm.nih.gov/articles/PMC2474742/). Note the parameters,\n",
    "\n",
    "1. `v` the drift rate (how much evidence do I collect on average per unit of time)\n",
    "2. `a` the boundary separation (how much evidence do I need to commit to a choice)\n",
    "3. `z` how biased am I toward a particular choice a priori\n",
    "4. `ndt` (we will simply call it `t` below), the delay between being exposed to a stimulus and starting the actual evidence accumulation process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BasicDDMModel = hssm.HSSM(data = workshop_data,\n",
    "                          model = \"ddm\",\n",
    "                          loglik_kind = \"approx_differentiable\",\n",
    "                          global_formula = \"y ~ 1\",\n",
    "                          noncentered = False,\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BasicDDMModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BasicDDMModel.graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Load pre-computed traces\n",
    "    BasicDDMModel.restore_traces(traces = \"idata/basic_ddm/traces.nc\")\n",
    "except:\n",
    "    # Sample posterior\n",
    "    basic_ddm_idata = BasicDDMModel.sample(chains = 2,\n",
    "                                            sampler = \"nuts_numpyro\",\n",
    "                                            tune = 500,\n",
    "                                            draws = 500,\n",
    "                                        )\n",
    "\n",
    "    # Sample posterior predictive\n",
    "    BasicDDMModel.sample_posterior_predictive(draws = 200,\n",
    "                                              safe_mode = True)\n",
    "\n",
    "    # Save Model\n",
    "    BasicDDMModel.save_model(model_name = \"basic_ddm\",\n",
    "                             allow_absolute_base_path = True,\n",
    "                             base_path = \"idata/\",\n",
    "                             save_idata_only = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BasicDDMModel.traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(BasicDDMModel.traces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(BasicDDMModel.traces)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_forest(BasicDDMModel.traces)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_pair(BasicDDMModel.traces,\n",
    "             kind=\"kde\",\n",
    "             marginals=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = hssm.plotting.plot_model_cartoon(\n",
    "    BasicDDMModel,\n",
    "    n_samples=10,\n",
    "    bins=20,\n",
    "    plot_pp_mean=True,\n",
    "    plot_pp_samples=False,\n",
    "    n_trajectories=2,  # extra arguments for the underlying plot_model_cartoon() function\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = hssm.plotting.plot_quantile_probability(BasicDDMModel, \n",
    "                                             cond=\"quantile_difficulty\",\n",
    "                                             )\n",
    "ax.set_ylim(0, 3);\n",
    "# ax.set_xlim(-0.1, 1.1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = hssm.plotting.plot_quantile_probability(BasicDDMModel, \n",
    "                                             cond=\"costly_fail_condition\",\n",
    "                                             )\n",
    "ax.set_ylim(0, 3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = hssm.plotting.plot_quantile_probability(BasicDDMModel, \n",
    "                                             cond=\"response_l1_plotting\",\n",
    "                                             )\n",
    "ax.set_ylim(0, 3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Posterior predictive\n",
    "BasicDDMModel.plot_posterior_predictive(step = True, \n",
    "                                        col = 'participant_id',\n",
    "                                        col_wrap = 5,\n",
    "                                        bins = np.linspace(-5,5, 50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Taking stock\n",
    "\n",
    "We can observe a few patterns here. \n",
    "\n",
    "- First, cleary the reaction time distributions are not the same for every subject, we need to account for that.\n",
    "- Second, I does seem like the tail of the reaction time distribution is more graceful in for our predictions than it is in the original subject data. (This was less clear when looking only at the global pattern...)\n",
    "\n",
    "We will now adjust our model to tackle these patterns one by one. Let's begin by specializing our parameters by subject. \n",
    "\n",
    "In **Bayesian Inference** we approach this by introducing a **Hierarchy**, we assume that subject level parameters derive from a common **group distribution**.\n",
    "\n",
    "Inference then proceeds over the parameters of this group distribution, as well as the subject wise parameters. \n",
    "\n",
    "Hierarchies serve as a form of **regularization** of our parameter estimates, the group distribution allows us to share information between the single subject parameters estimates. \n",
    "\n",
    "You don't **have** to use a hierarchy, we could introduce a subject wise parameterization e.g. by simply treating `participant_id` as a **categorical** variable / collection of **dummy** variables without using any notion of a group distribution (and you are welcome to try this)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DDM Hierarchical\n",
    "\n",
    "Moving on to our first hierarchical model. As a first step, we will use our `global_formula` argument to `(1|participant_id)`, which is equivalent to `1 + (1|participant_id)`,\n",
    "(use `0 + (1|participant_id)` is you explicitly don't want to create an intercept).\n",
    "\n",
    "This will make all parameters of our model hierarchical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DDMHierModel = hssm.HSSM(data = workshop_data,\n",
    "                         model = \"ddm\",\n",
    "                         loglik_kind = \"approx_differentiable\",\n",
    "                         global_formula = \"y ~ (1|participant_id)\", # New\n",
    "                         noncentered = False,\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Load pre-computed traces\n",
    "    DDMHierModel.restore_traces(traces = \"idata/ddm_hier/traces.nc\")\n",
    "except:\n",
    "    # Sample posterior\n",
    "    ddm_hier_idata = DDMHierModel.sample(chains = 2,\n",
    "                                             sampler = \"nuts_numpyro\",\n",
    "                                             tune = 500,\n",
    "                                             draws = 500,\n",
    "                                            )\n",
    "\n",
    "    # Sample posterior predictive\n",
    "    DDMHierModel.sample_posterior_predictive(draws = 200,\n",
    "                                             safe_mode = True)\n",
    "\n",
    "    # Save Model\n",
    "    DDMHierModel.save_model(model_name = \"ddm_hier\",\n",
    "                              allow_absolute_base_path = True,\n",
    "                              base_path = \"idata/\",\n",
    "                              save_idata_only = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DDMHierModel.graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(DDMHierModel.traces)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = hssm.plotting.plot_model_cartoon(\n",
    "    DDMHierModel,\n",
    "    col = \"participant_id\",\n",
    "    col_wrap = 5,\n",
    "    n_samples=100,\n",
    "    bin_size=0.2,\n",
    "    plot_pp_mean=True,\n",
    "    # color_pp_mean = \"red\",\n",
    "    # color_pp = \"black\",\n",
    "    plot_pp_samples=False,\n",
    "    n_trajectories=2,  # extra arguments for the underlying plot_model_cartoon() function\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing Parameter Loadings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(DDMHierModel.traces,\n",
    "           filter_vars = \"like\",\n",
    "           var_names = [\"~participant_id\"]).sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(BasicDDMModel.traces).sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean parameters of our models are de facto quite similar. Allowing subject wise variation however dramatically improved our fit to the data!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quantitative Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.compare(\n",
    "    {\"DDM\": BasicDDMModel.traces, \n",
    "     \"DDM Hierarchical\": DDMHierModel.traces}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Posterior predictive\n",
    "DDMHierModel.plot_posterior_predictive(step = True, \n",
    "                                       col_wrap = 5,\n",
    "                                       bins = np.linspace(-5,5, 50));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Posterior predictive\n",
    "BasicDDMModel.plot_posterior_predictive(step = True, \n",
    "                                        col_wrap = 5,\n",
    "                                        bins = np.linspace(-5,5, 50));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Posterior predictive\n",
    "DDMHierModel.plot_posterior_predictive(step = True, \n",
    "                                       col = 'participant_id',\n",
    "                                       col_wrap = 5,\n",
    "                                       bins = np.linspace(-5,5, 50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Taking Stock\n",
    "\n",
    "Let's take stock again of any obvious pontential for improving our model here. We are now capturing the data much better subject by subject, however looking closely, \n",
    "\n",
    "it seems like the tail behavior of the observed and the predicted data is somewhat different, for a few subjects. \n",
    "\n",
    "The particularly suspicious subjest, are:\n",
    "\n",
    "- `participant_id = 1`\n",
    "- `participant_id = 14`\n",
    "- `participant_id = 15`\n",
    "- `participant_id = 17`\n",
    "\n",
    "\n",
    "It seems that for these (and there are others) participants, the model predicted data has a wider tail than what we actually observe in our dataset. \n",
    "\n",
    "This will motivate a change in the Sequential Sampling Model that we apply. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Angle Model Hierarchical\n",
    "\n",
    "Given what we concluded about the tail behavior of the observed RTs, we will adjust our SSM, to allow for **linear collapsing bounds**. HSSM ships with a such a model,\n",
    "and we can apply it to our data simple by changing the `model` argument. The corresponding model is called `angle` model in our lingo, and is illustrated below conceptually.\n",
    "\n",
    "\n",
    "\n",
    "<center> <img src=\"./images/ANGLE_with_params_pic.png\" height=500 width=500> </center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AngleHierModel = hssm.HSSM(data = workshop_data,\n",
    "                           model = \"angle\",\n",
    "                           loglik_kind = \"approx_differentiable\",\n",
    "                           global_formula = \"y ~ (1|participant_id)\",\n",
    "                           noncentered = False,\n",
    "                          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AngleHierModel.graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Load pre-computed traces\n",
    "    AngleHierModel.restore_traces(traces = \"idata/angle_hier/traces.nc\")\n",
    "except:\n",
    "    # Sample posterior\n",
    "    angle_hier_idata = AngleHierModel.sample(chains = 2,\n",
    "                                             sampler = \"nuts_numpyro\",\n",
    "                                             tune = 500,\n",
    "                                             draws = 500,\n",
    "                                            )\n",
    "\n",
    "    # Sample posterior predictive\n",
    "    AngleHierModel.sample_posterior_predictive(draws = 200,\n",
    "                                               safe_mode = True)\n",
    "\n",
    "    # Save Model\n",
    "    AngleHierModel.save_model(model_name = \"angle_hier\",\n",
    "                              allow_absolute_base_path = True,\n",
    "                              base_path = \"idata/\",\n",
    "                              save_idata_only = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = hssm.plotting.plot_model_cartoon(\n",
    "    AngleHierModel,\n",
    "    col = 'participant_id',\n",
    "    col_wrap = 5,\n",
    "    n_samples=10,\n",
    "    bin_size=0.2,\n",
    "    plot_pp_mean=True,\n",
    "    plot_pp_samples=False,\n",
    "    n_trajectories=2,  # extra arguments for the underlying plot_model_cartoon() function\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can up it one notch and include the parameter uncertainty in the `model_cartoon_plot()`. This helps us assess how certain we are about the setting of the boundary collapse here.\n",
    "Let's see what that looks like!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = hssm.plotting.plot_model_cartoon(\n",
    "    AngleHierModel,\n",
    "    col = 'participant_id',\n",
    "    col_wrap = 5,\n",
    "    n_samples=50,\n",
    "    bin_size=0.2,\n",
    "    plot_pp_mean=True,\n",
    "    plot_pp_samples=True,\n",
    "    n_trajectories=2,  # extra arguments for the underlying plot_model_cartoon() function\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Angle (theta) parameter Bayesian t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_posterior(AngleHierModel.traces,\n",
    "                  var_names = [\"theta\"],\n",
    "                  ref_val = 0,\n",
    "                  kind = \"hist\",\n",
    "                  ref_val_color = \"red\",\n",
    "                  histtype = \"step\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Posterior predictive\n",
    "AngleHierModel.plot_posterior_predictive(step = True, \n",
    "                                         col_wrap = 5,\n",
    "                                         bins = np.linspace(-5,5, 50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Posterior predictive\n",
    "AngleHierModel.plot_posterior_predictive(step = True, \n",
    "                                        col = 'participant_id',\n",
    "                                        col_wrap = 5,\n",
    "                                        bins = np.linspace(-5,5, 50))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visually it seems like we did improve the fit (even though the difference in visual improvement is much less than what we had witnessed introducing the hierarchy in the first place). \n",
    "\n",
    "Let us corroborate the visual intuition via formal model comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quantitative Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.compare(\n",
    "    {\"DDM\": BasicDDMModel.traces,\n",
    "     \"DDM Hierarchical\": DDMHierModel.traces,\n",
    "     \"Angle Hierarchical\": AngleHierModel.traces}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good, introducing the `angle` model seemed to have helped us quite a bit, even though, as intuited by the simple visual inspection, the improvement in `elpd_loo` is not as \n",
    "the improvement in going from a simple model toward a hierarchical model (even though the actual SSM was misspecified).\n",
    "\n",
    "So what next? On the surface, it looks like we have a model that fits our data quite well. \n",
    "\n",
    "\n",
    "Let's take another look at our data to identify more patterns that we may not capture with out current efforts.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further EDA\n",
    "\n",
    "Maybe it is time to look more directly at the effects of our experiment manipulations.\n",
    "\n",
    "Below are a few graphs to understand what might be happening."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Posterior predictive\n",
    "AngleHierModel.plot_posterior_predictive(step = True, \n",
    "                                         col = 'costly_fail_condition',\n",
    "                                         bins = np.linspace(-5,5, 50))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = hssm.plotting.plot_quantile_probability(AngleHierModel, \n",
    "                                             cond=\"costly_fail_condition\",\n",
    "                                             )\n",
    "ax.set_ylim(0, 3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rt_hists(workshop_data,\n",
    "              by_participant = True,\n",
    "              split_by_column = \"costly_fail_condition\",\n",
    "              inset_plot =  \"choice_proportion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rt_hists(workshop_data,\n",
    "              by_participant = True,\n",
    "              split_by_column = \"costly_fail_condition\",\n",
    "              inset_plot =  \"rt_mean\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can identify two patterns. \n",
    "\n",
    "1. On average in the `costly_fail_condition` participants seem to make slightly fewer mistakes\n",
    "2. On average in the `costly_fail_condition` participants seem to take a little longer for their choices!\n",
    "\n",
    "This meshes with how we expect the incentives to act. Participants should be slightly more cautious to get it right, if mistakes are costly!\n",
    "\n",
    "In the contect of SSMs, this is usually mapped on to the `decision threshold` (parameter `a`), so maybe we should try to incorporate the `costly_fail_condition` in the regression\n",
    "function for that parameter in our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Addressing costly fail condition\n",
    "\n",
    "\n",
    "To include parameter specific regressions, we can rely on the `include` argument in HSSM. Let's illustrate this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AngleHierModelV2 = hssm.HSSM(data = workshop_data,\n",
    "                             model = \"angle\",\n",
    "                             loglik_kind = \"approx_differentiable\",\n",
    "                             global_formula = \"y ~ (1|participant_id)\",\n",
    "                             include = [{\"name\": \"a\",\n",
    "                                         \"formula\": \"a ~ (1 + C(costly_fail_condition)|participant_id)\"}],\n",
    "                             noncentered = False,\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AngleHierModelV2.graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Load pre-computed traces\n",
    "    AngleHierModelV2.restore_traces(traces = \"idata/angle_hier_v2/traces.nc\")\n",
    "except:\n",
    "    # Sample posterior\n",
    "    angle_hier_idata = AngleHierModelV2.sample(chains = 2,\n",
    "                                             sampler = \"nuts_numpyro\",\n",
    "                                             tune = 500,\n",
    "                                             draws = 500,\n",
    "                                            )\n",
    "\n",
    "    # Sample posterior predictive\n",
    "    AngleHierModelV2.sample_posterior_predictive(draws = 200,\n",
    "                                                 safe_mode = True)\n",
    "\n",
    "    # Save Model\n",
    "    AngleHierModelV2.save_model(model_name = \"angle_hier_v2\",\n",
    "                                allow_absolute_base_path = True,\n",
    "                                base_path = \"idata/\",\n",
    "                                save_idata_only = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(AngleHierModelV2.traces)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_posterior(AngleHierModelV2.traces,\n",
    "                  var_names = [\"a_C(costly_fail_condition)|participant_id_mu\"],\n",
    "                  ref_val = 0,\n",
    "                  kind = \"hist\",\n",
    "                  ref_val_color = \"red\",\n",
    "                  histtype = \"step\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Posterior predictive\n",
    "AngleHierModelV2.plot_posterior_predictive(step = True, \n",
    "                                           # row = 'participant_id',\n",
    "                                           col = 'costly_fail_condition',\n",
    "                                           bins = np.linspace(-5, 5, 50),\n",
    "                                           )\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = hssm.plotting.plot_quantile_probability(AngleHierModelV2, \n",
    "                                             cond=\"costly_fail_condition\",\n",
    "                                             )\n",
    "ax.set_ylim(0, 3);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quite an improvement!\n",
    "Let's see what our quantitative model comparison metrics say.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantitative Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.compare(\n",
    "    {\"DDM\": BasicDDMModel.traces,\n",
    "     \"DDM Hierarchical\": DDMHierModel.traces,\n",
    "     \"Angle Hierarchical\": AngleHierModel.traces,\n",
    "     \"Angle Hierarchical Cost\": AngleHierModelV2.traces}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good, we now incorporated the `costly_fail_condition` in a conceptually coherent manner. \n",
    "\n",
    "Let's take a look at `difficulty` next. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = hssm.plotting.plot_quantile_probability(AngleHierModelV2, \n",
    "                                             cond=\"quantile_difficulty_binary\",\n",
    "                                             )\n",
    "ax.set_ylim(0, 3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rt_hists(workshop_data,\n",
    "              by_participant = True,\n",
    "              split_by_column = \"quantile_difficulty_binary\",\n",
    "              inset_plot =  \"rt_mean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rt_hists(workshop_data,\n",
    "              by_participant = True,\n",
    "              split_by_column = \"quantile_difficulty_binary\",\n",
    "              inset_plot =  \"choice_proportion\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see a similar pattern. Difficulty affects choice probability, however the effect on RT is less clear.\n",
    "\n",
    "What parameter should difficulty map onto? Usually it maps onto the **rate of evidence accumulation**, which is the *drift* (`v`) parameter most SSMs.\n",
    "\n",
    "We will move ahead and try this. To add specialized regression for `v` we can add another parameter dictionary to the list we pass to `include`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Addressing difficulty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AngleHierModelV3 = hssm.HSSM(data = workshop_data,\n",
    "                             model = \"angle\",\n",
    "                             loglik_kind = \"approx_differentiable\",\n",
    "                             global_formula = \"y ~ (1|participant_id)\",\n",
    "                             include = [{\"name\": \"a\",\n",
    "                                         \"formula\": \"a ~ (1 + C(costly_fail_condition)|participant_id)\"},\n",
    "                                         {\"name\": \"v\",\n",
    "                                         \"formula\": \"v ~ (1 + continuous_difficulty|participant_id)\"},\n",
    "                                        ],\n",
    "                             noncentered = False,\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AngleHierModelV3.graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Load pre-computed traces\n",
    "    AngleHierModelV3.restore_traces(traces = \"idata/angle_hier_v3/traces.nc\")\n",
    "except:\n",
    "    # Sample posterior\n",
    "    angle_hier_idata = AngleHierModelV3.sample(chains = 2,\n",
    "                                             sampler = \"nuts_numpyro\",\n",
    "                                             tune = 500,\n",
    "                                             draws = 500,\n",
    "                                            )\n",
    "\n",
    "    # Sample posterior predictive\n",
    "    AngleHierModelV3.sample_posterior_predictive(draws = 200,\n",
    "                                                 safe_mode = True)\n",
    "\n",
    "    # Save Model\n",
    "    AngleHierModelV3.save_model(model_name = \"angle_hier_v3\",\n",
    "                                allow_absolute_base_path = True,\n",
    "                                base_path = \"idata/\",\n",
    "                                save_idata_only = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_posterior(AngleHierModelV3.traces,\n",
    "                  var_names = [\"v_continuous_difficulty|participant_id_mu\"],\n",
    "                  ref_val = 0,\n",
    "                  kind = \"hist\",\n",
    "                  ref_val_color = \"red\",\n",
    "                  histtype = \"step\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the effect on `v` is small (to the trained eye :)), but it is significant!\n",
    "Let's check if we can account for the data pattern we missed previously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = hssm.plotting.plot_quantile_probability(AngleHierModelV3, \n",
    "                                             cond=\"quantile_difficulty_binary\",\n",
    "                                             )\n",
    "ax.set_ylim(0, 3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Posterior predictive\n",
    "AngleHierModelV3.plot_posterior_predictive(step = True, \n",
    "                                           col = \"quantile_difficulty_binary\",\n",
    "                                           bins = np.linspace(-5,5, 50))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Success! This looks much better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quantitative Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.compare(\n",
    "    {\n",
    "     \"DDM\": BasicDDMModel.traces,\n",
    "     \"DDM Hierarchical\": DDMHierModel.traces,\n",
    "     \"Angle Hierarchical\": AngleHierModel.traces,\n",
    "     \"Angle Hierarchical Cost\": AngleHierModelV2.traces,\n",
    "     \"Angle Hierarchical Cost/Diff\": AngleHierModelV3.traces\n",
    "     }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anything else?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we have a model that fits the data quite well. \n",
    "\n",
    "We figured that a hierarchy significantly improves our fit, that the `angle` model dominates the basic `ddm` model for our data, and we incorporated effects based on \n",
    "our experiment manipulations. \n",
    "\n",
    "A natural next step is to check for patterns based on more generic properties of human choice data that we may be able to reason about. \n",
    "\n",
    "Anything that comes to mind? Let's take another look at our dataset for some inspiration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workshop_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At risk of stating the obvious,we have a column that went unused thus far: `response_l1`, the lagged response.\n",
    "\n",
    "Maybe this hints at some level of *stickiness* in the choice behavior? How could we incorporate this?\n",
    "\n",
    "Let us first investigate if there is indeed such a pattern in the data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Posterior predictive\n",
    "AngleHierModelV3.plot_posterior_predictive(step = True, \n",
    "                                           col = 'response_l1_plotting',\n",
    "                                           bins = np.linspace(-5, 5, 50))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, it does seem like there is a bit of a pattern here, that we miss so far!\n",
    "\n",
    "To incoporate choice `stickiness`, a reasonable candidate parameter is `z`, the a priori choice bias. \n",
    "Maybe this parameter is affected by the last choice taken?\n",
    "\n",
    "Let's try to incoporate this. We will "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Addressing Stickyness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AngleHierModelV4 = hssm.HSSM(data = workshop_data,\n",
    "                             model = \"angle\",\n",
    "                             loglik_kind = \"approx_differentiable\",\n",
    "                             global_formula = \"y ~ (1|participant_id)\",\n",
    "                             include = [{\"name\": \"a\",\n",
    "                                         \"formula\": \"a ~ (1 + C(costly_fail_condition)|participant_id)\"},\n",
    "                                         {\"name\": \"v\",\n",
    "                                          \"formula\": \"v ~ (1 + continuous_difficulty|participant_id)\"},\n",
    "                                         {\"name\": \"z\",\n",
    "                                          \"formula\": \"z ~ (1 + response_l1|participant_id)\"},\n",
    "                                        ],\n",
    "                             noncentered = False,\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AngleHierModelV4.graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Load pre-computed traces\n",
    "    AngleHierModelV4.restore_traces(traces = \"idata/angle_hier_v4/traces.nc\")\n",
    "except:\n",
    "    # Sample posterior\n",
    "    angle_hier_idata = AngleHierModelV4.sample(chains = 2,\n",
    "                                             sampler = \"nuts_numpyro\",\n",
    "                                             tune = 500,\n",
    "                                             draws = 500,\n",
    "                                            )\n",
    "\n",
    "    # Sample posterior predictive\n",
    "    AngleHierModelV4.sample_posterior_predictive(draws = 200,\n",
    "                                                 safe_mode = True)\n",
    "\n",
    "    # Save Model\n",
    "    AngleHierModelV4.save_model(model_name = \"angle_hier_v4\",\n",
    "                                allow_absolute_base_path = True,\n",
    "                                base_path = \"idata/\",\n",
    "                                save_idata_only = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(AngleHierModelV4.traces,\n",
    "              divergences = None);\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Note **:\n",
    "\n",
    "We can see some rather interesting artifacts in the chains above. Around samples `300-375` it looks like our solid-blue chain got quite stuck. This indicates some problems with the posterior geometry for this model. \n",
    "One diagnostic that can be helpful here whether or not we observe a lot of `divergences` during sampling. \n",
    "\n",
    "Let's take a look below (notice, we change the `diveregences` argument from `None` to it's default)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(AngleHierModelV4.traces,\n",
    "              divergences = 'auto');\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, we observe a fee divergences here... as rigorous scientists, we should now try to get to the bottom of this phenomenon (it happens often if one tries hierarchical models naively on real experimental data).\n",
    "In the context of this tutorial, we will let it slide however. It would warrant a longer detour.\n",
    "\n",
    "Let's move on and focus on whether or not we actually identify a significant **choice stickyness** effect with our analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_posterior(AngleHierModelV4.traces,\n",
    "                  var_names = [\"z_response_l1|participant_id_mu\"],\n",
    "                  ref_val = 0,\n",
    "                  kind = \"hist\",\n",
    "                  ref_val_color = \"red\",\n",
    "                  histtype = \"step\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe a significant effect on the `z` parameter, in fact a mean effect of `0.073` insinuate a fairly big effect of choice stickyness.\n",
    "In direct comparison, we might expect this effect to overall have a larger impact on our model fit than the effect of difficulty on `v`, which we investigated in the \n",
    "previous section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Posterior predictive\n",
    "AngleHierModelV4.plot_posterior_predictive(step = True, \n",
    "                                           col = 'response_l1_plotting',\n",
    "                                           bins = np.linspace(-5, 5, 50))\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quantitative Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.compare(\n",
    "    {\"DDM\": BasicDDMModel.traces,\n",
    "     \"DDM Hierarchical\": DDMHierModel.traces,\n",
    "     \"Angle Hierarchical\": AngleHierModel.traces,\n",
    "     \"Angle Hierarchical Cost\": AngleHierModelV2.traces,\n",
    "     \"Angle Hierarchical Cost/Diff\": AngleHierModelV3.traces,\n",
    "     \"Angle Hierarchical Cost/Diff/Sticky\": AngleHierModelV4.traces}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And indeed, the drop in`elpd_loo` is even more substantial, than the improvement generated by incorporating the `difficulty` effect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Taking Stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = hssm.plotting.plot_quantile_probability(AngleHierModelV4, \n",
    "                                             cond=\"response_l1_plotting\",\n",
    "                                             )\n",
    "ax.set_ylim(0, 3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = hssm.plotting.plot_quantile_probability(AngleHierModelV4, \n",
    "                                             cond=\"costly_fail_condition\",\n",
    "                                             )\n",
    "ax.set_ylim(0, 3);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = hssm.plotting.plot_quantile_probability(AngleHierModelV4, \n",
    "                                             cond=\"quantile_difficulty_binary\",\n",
    "                                             )\n",
    "ax.set_ylim(0, 3);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sanity Check, was the hierarchy really necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AngleModelV5 = hssm.HSSM(data = workshop_data,\n",
    "                         model = \"angle\",\n",
    "                         loglik_kind = \"approx_differentiable\",\n",
    "                         global_formula = \"y ~ 1\",\n",
    "                         include = [{\"name\": \"a\",\n",
    "                                        \"formula\": \"a ~ 1 + C(costly_fail_condition)\"},\n",
    "                                        {\"name\": \"v\",\n",
    "                                        \"formula\": \"v ~ 1 + continuous_difficulty\"},\n",
    "                                        {\"name\": \"z\",\n",
    "                                        \"formula\": \"z ~ 1 + response_l1\"},\n",
    "                                    ],\n",
    "                         noncentered = False,\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Load pre-computed traces\n",
    "    AngleModelV5.restore_traces(traces = \"idata/angle_v5/traces.nc\")\n",
    "except:\n",
    "    # Sample posterior\n",
    "    angle_hier_idata = AngleModelV5.sample(chains = 2,\n",
    "                                           sampler = \"nuts_numpyro\",\n",
    "                                           tune = 500,\n",
    "                                           draws = 500,\n",
    "                                           )\n",
    "\n",
    "    # Sample posterior predictive\n",
    "    AngleModelV5.sample_posterior_predictive(draws = 200,\n",
    "                                                 safe_mode = True)\n",
    "\n",
    "    # Save Model\n",
    "    AngleModelV5.save_model(model_name = \"angle_v5\",\n",
    "                            allow_absolute_base_path = True,\n",
    "                            base_path = \"idata/\",\n",
    "                            save_idata_only = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.compare(\n",
    "    {\n",
    "     \"DDM\": BasicDDMModel.traces,\n",
    "     \"DDM Hierarchical\": DDMHierModel.traces,\n",
    "     \"Angle Hierarchical\": AngleHierModel.traces,\n",
    "     \"Angle Hierarchical Cost\": AngleHierModelV2.traces,\n",
    "     \"Angle Hierarchical Cost/Diff\": AngleHierModelV3.traces,\n",
    "     \"Angle Hierarchical Cost/Diff/Sticky\": AngleHierModelV4.traces,\n",
    "     \"Angle Cost/Diff/Sticky\": AngleModelV5.traces\n",
    "     }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The End:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far so good, we completed a rather comprehensive model exploration and we generated quite a few insights!\n",
    "We could obviously go on and try more and more complex models and maybe there is more to find out here... we leave this up to you and hope that HSSM will continue to help you along the way :)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pointers to advanced Topics\n",
    "\n",
    "We are scratching only the surface of what cann be done with [HSSM](https://github.com/lnccbrown/HSSM/), let alone the broader eco-system supporting [simulation based inference (SBI)](https://simulation-based-inference.org/).\n",
    "\n",
    "Check out our simulator package, [ssm-simulators](https://github.com/lnccbrown/ssm-simulators) as well as our our little neural network library for training [LANs](https://elifesciences.org/articles/65074), [lanfactory](https://github.com/lnccbrown/LANfactory). \n",
    "\n",
    "Exciting work is being done (more on this in the next tutorial) on connecting to other packages in the wider eco-system, such as [BayesFlow](https://bayesflow.org/main/index.html) as well as the [sbi](https://sbi-dev.github.io/sbi/v0.24.0/) package.\n",
    "\n",
    "Here is a taste of advanced topics with links to corresponding tutorials:\n",
    "\n",
    "- [Variational Inference with HSSM](https://lnccbrown.github.io/HSSM/tutorials/variational_inference/)\n",
    "- [Build PyMC models with HSSM random variables](https://lnccbrown.github.io/HSSM/tutorials/pymc/)\n",
    "- [Connect compiled models to third party MCMC libraries](https://lnccbrown.github.io/HSSM/tutorials/compile_logp/)\n",
    "- [Construct custom models from simulators and contributed likelihoods](https://lnccbrown.github.io/HSSM/tutorials/jax_callable_contribution_onnx_example/)\n",
    "- [Using link functions to transform parameters](https://lnccbrown.github.io/HSSM/api/link/#hssm.Link)\n",
    "\n",
    "you will find this and a lot more information in the [official documentation](https://lnccbrown.github.io/HSSM/)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
