{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0aec427c-56d5-48bb-83c6-6bdc0c445ba2",
   "metadata": {},
   "source": [
    "# Hierarchical Modeling\n",
    "\n",
    "This tutorial demonstrates how to take advantage of HSSM's hierarchical modeling capabilities. We will cover the following:\n",
    "\n",
    "- How to define a mixed-effect regression\n",
    "- How to define a hierarchial HSSM model\n",
    "- How to apply prior and link function settings to ensure successful sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36aafcf1-e703-40e3-b11d-4ab5ad74655f",
   "metadata": {},
   "source": [
    "## Colab Instructions\n",
    "\n",
    "If you would like to run this tutorial on Google colab, please click this [link](https://github.com/lnccbrown/HSSM/blob/main/docs/tutorial_notebooks/no_execute/getting_started.ipynb). \n",
    "\n",
    "Once you are *in the colab*, follow the *installation instructions below* and then **restart your runtime**. \n",
    "\n",
    "Just **uncomment the code in the next code cell** and run it!\n",
    "\n",
    "**NOTE**:\n",
    "\n",
    "You may want to *switch your runtime* to have a GPU or TPU. To do so, go to *Runtime* > *Change runtime type* and select the desired hardware accelerator.\n",
    "\n",
    "Note that if you switch your runtime you have to follow the installation instructions again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61937b47-810d-41b6-a6b8-e461c5e5ae71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install hssm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650b011a-62b3-4243-9ed7-2087b2f232cd",
   "metadata": {},
   "source": [
    "## Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11fc424e-2aff-49b0-b1a9-d54c7d7f67be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hssm\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d671ab29-710a-47ab-af79-32fac7891318",
   "metadata": {},
   "source": [
    "### Setting the global float type\n",
    "\n",
    "**Note**: Using the analytical DDM (Drift Diffusion Model) likelihood in PyMC without setting the float type in `PyTensor` may result in warning messages during sampling, which is a known bug in PyMC v5.6.0 and earlier versions. To avoid these warnings, we provide a convenience function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01314abb-6ee5-4fc5-975e-002768fde007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting PyTensor floatX type to float32.\n",
      "Setting \"jax_enable_x64\" to False. If this is not intended, please set `jax` to False.\n"
     ]
    }
   ],
   "source": [
    "hssm.set_floatX(\"float32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2fcd33e-46e0-41fe-8fd6-26eedd39aec0",
   "metadata": {},
   "source": [
    "## 1. Defining Regressions\n",
    "\n",
    "Under the hood, HSSM uses [`bambi`](https://bambinos.github.io/bambi/) for model creation. `bambi` takes inspiration from the [`lme4` package in R](https://www.rdocumentation.org/packages/lme4/versions/1.1-35.1/topics/lmer) and supports the definition of generalized linear mixed-effect models through\n",
    "R-like formulas and concepts such as link functions. This makes it possible to create arbitrary mixed-effect regressions in HSSM, which is one advantage of HSSM over HDDM. Now let's walk through the ways to define a parameter with a regression in HSSM.\n",
    "\n",
    "### Specifying fixed- and random-effect terms\n",
    "\n",
    "Suppose that we want to define a parameter `v` that has a regression defined. There are two ways to define such a parameter - either through a dictionary\n",
    "or through a `hssm.Param` object:\n",
    "\n",
    "```\n",
    "# The following code are equivalent,\n",
    "# including the definition of the formula.\n",
    "\n",
    "# The dictionary way:\n",
    "param_v = {\n",
    "    \"name\": \"v\",\n",
    "    \"formula\": \"v ~ x + y + x:y + (1|participant_id)\",\n",
    "    \"link\": \"identity\",\n",
    "    \"prior\": {\n",
    "        \"Intercept\": {\"name\": \"Normal\", \"mu\": 0.0, \"sigma\": 0.25},\n",
    "        \"1|participant_id\": {\n",
    "            \"name\": \"Normal\",\n",
    "            \"mu\": 0.0,\n",
    "            \"sigma\": {\"name\": \"HalfNormal\", \"sigma\": 0.2},  # this is a hyperprior\n",
    "        },\n",
    "        \"x\": {\"name\": \"Normal\", \"mu\": 0.0, \"sigma\": 0.25},\n",
    "    },\n",
    "}\n",
    "\n",
    "# The object-oriented way\n",
    "param_v = hssm.Param(\n",
    "    \"v\",\n",
    "    formula=\"v ~ 1 + x*y + (1|participant_id)\",\n",
    "    link=\"identity\",\n",
    "    prior={\n",
    "        \"Intercept\": hssm.Prior(\"Normal\", mu=0.0, sigma=0.25),\n",
    "        \"1|participant_id\": hssm.Prior(\n",
    "            \"Normal\",\n",
    "            mu=0.0,\n",
    "            sigma=hssm.Prior(\"HalfNormal\", sigma=0.2), # this is a hyperprior\n",
    "        ),\n",
    "        \"x\": hssm.Prior(\"Normal\", mu=0.0, sigma=0.25),\n",
    "    },\n",
    ")\n",
    "```\n",
    "\n",
    "The formula `\"v ~ x + y + x:y + (1|participant_id)\"` defines a random-intercept model. Like R, unless otherwise specified, a fixed-effect intercept term is added to the formula by default. You can make this explicit by adding a `1` to the formula. Or, if your regression does not have an intercept. you can explicitly remove the intercept term by using a `0` in the place of `1`: `\"v ~ 0 + x * y + (1|participant_id)\"`. **We recommend that the random effect terms should be specified after the fixed effect terms.**\n",
    "\n",
    "Other fixed effect covariates are `x`, `y`, and the interaction term `x:y`. When all three terms are present, you can use the shortcut `x * y` in place of the three terms.\n",
    "\n",
    "The only random effect term in this model is `1|participant_id`. It is a random-intercept term with `participant_id` indicating the grouping variable. You can add another random-effect term in a similar way: `\"v ~ x + y + x:y + (1|participant_id) + (x|participant_id)\"`, or more briefly, `\"v ~ x + y + x:y + (1 + x|participant_id)\"`.\n",
    "\n",
    "### Specifying priors for fixed- and random-effect terms:\n",
    "\n",
    "As demonstrated in the above code, you can specify priors of each term through a dictionary, with the key being the name of each term, and the corresponding value being the prior specification, etiher through a dictionary, or a `hssm.Prior` object. There are a few things to note:\n",
    "\n",
    "* The prior of fixed-effect intercept is specified with `\"Intercept\"`, capitalized.\n",
    "* For random effects, you can specify hyperpriors for the parameters of of their priors.\n",
    "\n",
    "### Specifying the link functions:\n",
    "\n",
    "Link functions is another concept in frequentist generalized linear models, which defines a transformation between the linear combination of the covariates and the response variable. This is helpful especially when the response variable is not normally distributed, e.g. in a logistic regression. In HSSM, the link function is identity by default. However, since some parameters of SSMs are defined on `(0, inf)` or `(0, 1)`, link function can be helpful in ensuring the result of the regression is defined for these parameters. We will come back to this later."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb603f1-dc4f-44d3-b12f-e4a460d2d9f9",
   "metadata": {},
   "source": [
    "## 2. Defining a hierarchical HSSM model\n",
    "\n",
    "In fact, HSSM does not differentiate between a hierarchical or non-hierarchical model. A hierarchical model in HSSM is simply a model with one or more parameters defined as regressions. However, HSSM does provide some useful functionalities in creating hierarchical models.\n",
    "\n",
    "### **BREAKING CHANGES:** Use `global_formula` instead of `hierarchical` parameter when creating an HSSM model\n",
    "\n",
    "In HSSM v0.2.5, we have removed the `hierarchical` parameter to the `hssm.HSSM` class. In older versions, HSSM had a `hierarchical` argument which was a `bool`. It serves as a convenient switch to add a random-intercept regression to any parameter that is not explicitly defined by the user, using `participant_id` as a grouping variable.\n",
    "\n",
    "However, this `hierarchical` parameter caused much confusion, because many believed that somehow `hierarchical` would magically turn the model into a hierarchical model, while in reality, it does nothing more than adding a `y ~ 1 + (1|participant_id)` to all parameter, where `y` stands for the name of that parameter. That is why we removed this confusing parameter in favor of the new `global_formula` parameter, which is less confusing and offers the users more convenience and transparent control over the models that they want to create.\n",
    "\n",
    "When specified, `global_formula` adds the specified formula to all parameters. Therefore, when set to `y ~ 1 + (1|participant_id)`, this is equivalent to setting `hierarchical=True` in older versions of HSSM. However, the users can set it to any formula they want to apply to all parameters. HSSM is agnostic to whatever parameter name to the left of the `~` sign, while using `y` is more customary.\n",
    "\n",
    "<div class=\"admonition note\">\n",
    "  <p class=\"admonition-title\">Note</p>\n",
    "  <p>\n",
    "    In HSSM, the default grouping variable is now `participant_id`, which is different from `subj_idx` in HDDM.\n",
    "  </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab2a960-e9e6-4043-996c-57742832de0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a package-supplied dataset\n",
    "cav_data = hssm.load_data(\"cavanagh_theta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c75438-c6c4-4589-8244-dac7ffc18eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Hierarchical Sequential Sampling Model\n",
       "Model: ddm\n",
       "\n",
       "Response variable: rt,response\n",
       "Likelihood: analytical\n",
       "Observations: 3988\n",
       "\n",
       "Parameters:\n",
       "\n",
       "v:\n",
       "    Prior: Normal(mu: 0.0, sigma: 2.0)\n",
       "    Explicit bounds: (-inf, inf)\n",
       "\n",
       "a:\n",
       "    Prior: HalfNormal(sigma: 2.0)\n",
       "    Explicit bounds: (0.0, inf)\n",
       "\n",
       "z:\n",
       "    Prior: Uniform(lower: 0.0, upper: 1.0)\n",
       "    Explicit bounds: (0.0, 1.0)\n",
       "\n",
       "t:\n",
       "    Prior: HalfNormal(sigma: 2.0)\n",
       "    Explicit bounds: (0.0, inf)\n",
       "\n",
       "\n",
       "Lapse probability: 0.05\n",
       "Lapse distribution: Uniform(lower: 0.0, upper: 20.0)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a basic non-hierarchical model\n",
    "model_non_hierarchical = hssm.HSSM(data=cav_data)\n",
    "model_non_hierarchical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cde1989-8d6b-437a-a972-940f0fd84904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Hierarchical Sequential Sampling Model\n",
       "Model: ddm\n",
       "\n",
       "Response variable: rt,response\n",
       "Likelihood: analytical\n",
       "Observations: 3988\n",
       "\n",
       "Parameters:\n",
       "\n",
       "v:\n",
       "    Formula: v ~ 1 + (1|participant_id)\n",
       "    Priors:\n",
       "        v_Intercept ~ Normal(mu: 2.0, sigma: 3.0)\n",
       "        v_1|participant_id ~ Normal(mu: 0.0, sigma: Weibull(alpha: 1.5, beta: 0.30000001192092896))\n",
       "    Link: identity\n",
       "    Explicit bounds: (-inf, inf)\n",
       "\n",
       "a:\n",
       "    Formula: a ~ 1 + (1|participant_id)\n",
       "    Priors:\n",
       "        a_Intercept ~ Gamma(mu: 1.5, sigma: 0.75)\n",
       "        a_1|participant_id ~ Normal(mu: 0.0, sigma: Weibull(alpha: 1.5, beta: 0.30000001192092896))\n",
       "    Link: identity\n",
       "    Explicit bounds: (0.0, inf)\n",
       "\n",
       "z:\n",
       "    Formula: z ~ 1 + (1|participant_id)\n",
       "    Priors:\n",
       "        z_Intercept ~ Beta(alpha: 10.0, beta: 10.0)\n",
       "        z_1|participant_id ~ Normal(mu: 0.0, sigma: Weibull(alpha: 1.5, beta: 0.30000001192092896))\n",
       "    Link: identity\n",
       "    Explicit bounds: (0.0, 1.0)\n",
       "\n",
       "t:\n",
       "    Formula: t ~ 1 + (1|participant_id)\n",
       "    Priors:\n",
       "        t_Intercept ~ Gamma(mu: 0.20000000298023224, sigma: 0.20000000298023224)\n",
       "        t_1|participant_id ~ Normal(mu: 0.0, sigma: Weibull(alpha: 1.5, beta: 0.30000001192092896))\n",
       "    Link: identity\n",
       "    Explicit bounds: (0.0, inf)\n",
       "\n",
       "\n",
       "Lapse probability: 0.05\n",
       "Lapse distribution: Uniform(lower: 0.0, upper: 20.0)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specifying a global formula\n",
    "# This is equivalent to setting `hierarchical` to True\n",
    "model_hierarchical = hssm.HSSM(\n",
    "    data=cav_data, global_formula=\"y ~ 1 + (1|participant_id)\", prior_settings=\"safe\"\n",
    ")\n",
    "model_hierarchical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4baeb2f-c49e-4d63-a962-4c6f47f3f848",
   "metadata": {},
   "source": [
    "## 3. Intelligent defaults for complex hierarchical models\n",
    "\n",
    "`bambi` is not designed with HSSM in mind. Therefore, in cases where priors for certain parameters are not defined, the default priors supplied by `bambi` sometimes are not optimal. The same goes for link functions. `\"identity\"` link functions tend not to work well for certain parameters that are not defined on `(inf, inf)`. Therefore, we provide some default settings that the users can experiment to ensure that sampling is successful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b405fc-d508-468c-8fd8-12283ed03945",
   "metadata": {},
   "source": [
    "### `prior_settings`\n",
    "\n",
    "Currently we provide a `\"safe\"` strategy that uses HSSM default priors, which is turned on by default for parameters that are targets of regressions. One can compare the two models below, with `safe` strategy turned on and off:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145545e3-4712-4929-84c5-53ab3f8ae051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Hierarchical Sequential Sampling Model\n",
       "Model: ddm\n",
       "\n",
       "Response variable: rt,response\n",
       "Likelihood: approx_differentiable\n",
       "Observations: 3988\n",
       "\n",
       "Parameters:\n",
       "\n",
       "v:\n",
       "    Formula: v ~ 1 + (1|participant_id)\n",
       "    Priors:\n",
       "        v_Intercept ~ Normal(mu: 0.0, sigma: 0.25)\n",
       "        v_1|participant_id ~ Normal(mu: 0.0, sigma: Weibull(alpha: 1.5, beta: 0.30000001192092896))\n",
       "    Link: identity\n",
       "    Explicit bounds: (-3.0, 3.0)\n",
       "\n",
       "a:\n",
       "    Formula: a ~ 1 + (1|participant_id)\n",
       "    Priors:\n",
       "        a_Intercept ~ Normal(mu: 1.399999976158142, sigma: 0.25)\n",
       "        a_1|participant_id ~ Normal(mu: 0.0, sigma: Weibull(alpha: 1.5, beta: 0.30000001192092896))\n",
       "    Link: identity\n",
       "    Explicit bounds: (0.3, 2.5)\n",
       "\n",
       "z:\n",
       "    Formula: z ~ 1 + (1|participant_id)\n",
       "    Priors:\n",
       "        z_Intercept ~ Normal(mu: 0.5, sigma: 0.25)\n",
       "        z_1|participant_id ~ Normal(mu: 0.0, sigma: Weibull(alpha: 1.5, beta: 0.30000001192092896))\n",
       "    Link: identity\n",
       "    Explicit bounds: (0.0, 1.0)\n",
       "\n",
       "t:\n",
       "    Formula: t ~ 1 + (1|participant_id)\n",
       "    Priors:\n",
       "        t_Intercept ~ Normal(mu: 1.0, sigma: 0.25)\n",
       "        t_1|participant_id ~ Normal(mu: 0.0, sigma: Weibull(alpha: 1.5, beta: 0.30000001192092896))\n",
       "    Link: identity\n",
       "    Explicit bounds: (0.0, 2.0)\n",
       "\n",
       "\n",
       "Lapse probability: 0.05\n",
       "Lapse distribution: Uniform(lower: 0.0, upper: 20.0)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_safe = hssm.HSSM(\n",
    "    data=cav_data,\n",
    "    global_formula=\"y ~ 1 + (1|participant_id)\",\n",
    "    prior_settings=\"safe\",\n",
    "    loglik_kind=\"approx_differentiable\",\n",
    ")\n",
    "model_safe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea21e3d-e5e4-4bf3-a5a1-7aea1e9d9d00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Hierarchical Sequential Sampling Model\n",
       "Model: ddm\n",
       "\n",
       "Response variable: rt,response\n",
       "Likelihood: approx_differentiable\n",
       "Observations: 3988\n",
       "\n",
       "Parameters:\n",
       "\n",
       "v:\n",
       "    Formula: v ~ 1 + (1|participant_id)\n",
       "    Priors:\n",
       "        v_Intercept ~ Normal(mu: 0.0, sigma: 2.5)\n",
       "        v_1|participant_id ~ Normal(mu: 0.0, sigma: HalfNormal(sigma: 2.5))\n",
       "    Link: identity\n",
       "    Explicit bounds: (-3.0, 3.0)\n",
       "\n",
       "a:\n",
       "    Formula: a ~ 1 + (1|participant_id)\n",
       "    Priors:\n",
       "        a_Intercept ~ Normal(mu: 0.0, sigma: 1.0)\n",
       "        a_1|participant_id ~ Normal(mu: 0.0, sigma: HalfNormal(sigma: 1.0))\n",
       "    Link: identity\n",
       "    Explicit bounds: (0.3, 2.5)\n",
       "\n",
       "z:\n",
       "    Formula: z ~ 1 + (1|participant_id)\n",
       "    Priors:\n",
       "        z_Intercept ~ Normal(mu: 0.0, sigma: 1.0)\n",
       "        z_1|participant_id ~ Normal(mu: 0.0, sigma: HalfNormal(sigma: 1.0))\n",
       "    Link: identity\n",
       "    Explicit bounds: (0.0, 1.0)\n",
       "\n",
       "t:\n",
       "    Formula: t ~ 1 + (1|participant_id)\n",
       "    Priors:\n",
       "        t_Intercept ~ Normal(mu: 0.0, sigma: 1.0)\n",
       "        t_1|participant_id ~ Normal(mu: 0.0, sigma: HalfNormal(sigma: 1.0))\n",
       "    Link: identity\n",
       "    Explicit bounds: (0.0, 2.0)\n",
       "\n",
       "\n",
       "Lapse probability: 0.05\n",
       "Lapse distribution: Uniform(lower: 0.0, upper: 20.0)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_safe_off = hssm.HSSM(\n",
    "    data=cav_data,\n",
    "    global_formula=\"y ~ 1 + (1|participant_id)\",\n",
    "    prior_settings=None,\n",
    "    loglik_kind=\"approx_differentiable\",\n",
    ")\n",
    "model_safe_off"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99b6d77-b4a2-4813-8927-433b65d646a3",
   "metadata": {},
   "source": [
    "### `link_settings`\n",
    "\n",
    "We also provide a `link_settings` switch, which changes default link functions for parameters according to their explicit bounds. See the model below with `link_settings` set to `\"log_logit\"`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d0f895-8188-4e44-8946-ef80af2c4b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Hierarchical Sequential Sampling Model\n",
       "Model: ddm\n",
       "\n",
       "Response variable: rt,response\n",
       "Likelihood: analytical\n",
       "Observations: 3988\n",
       "\n",
       "Parameters:\n",
       "\n",
       "v:\n",
       "    Formula: v ~ 1 + (1|participant_id)\n",
       "    Priors:\n",
       "        v_Intercept ~ Normal(mu: 0.0, sigma: 2.5)\n",
       "        v_1|participant_id ~ Normal(mu: 0.0, sigma: HalfNormal(sigma: 2.5))\n",
       "    Link: identity\n",
       "    Explicit bounds: (-inf, inf)\n",
       " (ignored due to link function)\n",
       "a:\n",
       "    Formula: a ~ 1 + (1|participant_id)\n",
       "    Priors:\n",
       "        a_Intercept ~ Normal(mu: 0.0, sigma: 1.0)\n",
       "        a_1|participant_id ~ Normal(mu: 0.0, sigma: HalfNormal(sigma: 1.0))\n",
       "    Link: log\n",
       "    Explicit bounds: (0.0, inf)\n",
       " (ignored due to link function)\n",
       "z:\n",
       "    Formula: z ~ 1 + (1|participant_id)\n",
       "    Priors:\n",
       "        z_Intercept ~ Normal(mu: 0.0, sigma: 1.0)\n",
       "        z_1|participant_id ~ Normal(mu: 0.0, sigma: HalfNormal(sigma: 1.0))\n",
       "    Link: Generalized logit link function with bounds (0.0, 1.0)\n",
       "    Explicit bounds: (0.0, 1.0)\n",
       " (ignored due to link function)\n",
       "t:\n",
       "    Formula: t ~ 1 + (1|participant_id)\n",
       "    Priors:\n",
       "        t_Intercept ~ Normal(mu: 0.0, sigma: 1.0)\n",
       "        t_1|participant_id ~ Normal(mu: 0.0, sigma: HalfNormal(sigma: 1.0))\n",
       "    Link: log\n",
       "    Explicit bounds: (0.0, inf)\n",
       " (ignored due to link function)\n",
       "\n",
       "Lapse probability: 0.05\n",
       "Lapse distribution: Uniform(lower: 0.0, upper: 20.0)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_log_logit = hssm.HSSM(\n",
    "    data=cav_data,\n",
    "    global_formula=\"y ~ 1 + (1|participant_id)\",\n",
    "    prior_settings=None,\n",
    "    link_settings=\"log_logit\",\n",
    ")\n",
    "model_log_logit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc82d284-7164-4072-9a25-67fa8cc77b17",
   "metadata": {},
   "source": [
    "### Mixing strategies:\n",
    "\n",
    "It is possible to turn on both `prior_settings` and `link_settings`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6099bb5-2d55-4ef8-b08b-cee2edfa4bc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model initialized successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Hierarchical Sequential Sampling Model\n",
       "Model: ddm\n",
       "\n",
       "Response variable: rt,response\n",
       "Likelihood: analytical\n",
       "Observations: 3988\n",
       "\n",
       "Parameters:\n",
       "\n",
       "v:\n",
       "    Formula: v ~ 1 + (1|participant_id)\n",
       "    Priors:\n",
       "        v_Intercept ~ Normal(mu: 0.0, sigma: 0.25)\n",
       "        v_1|participant_id ~ Normal(mu: 0.0, sigma: Weibull(alpha: 1.5, beta: 0.30000001192092896))\n",
       "    Link: identity\n",
       "    Explicit bounds: (-inf, inf)\n",
       " (ignored due to link function)\n",
       "a:\n",
       "    Formula: a ~ 1 + (1|participant_id)\n",
       "    Priors:\n",
       "        a_Intercept ~ Normal(mu: 0.0, sigma: 0.25)\n",
       "        a_1|participant_id ~ Normal(mu: 0.0, sigma: Weibull(alpha: 1.5, beta: 0.30000001192092896))\n",
       "    Link: log\n",
       "    Explicit bounds: (0.0, inf)\n",
       " (ignored due to link function)\n",
       "z:\n",
       "    Formula: z ~ 1 + (1|participant_id)\n",
       "    Priors:\n",
       "        z_Intercept ~ Normal(mu: 0.0, sigma: 0.25)\n",
       "        z_1|participant_id ~ Normal(mu: 0.0, sigma: Weibull(alpha: 1.5, beta: 0.30000001192092896))\n",
       "    Link: Generalized logit link function with bounds (0.0, 1.0)\n",
       "    Explicit bounds: (0.0, 1.0)\n",
       " (ignored due to link function)\n",
       "t:\n",
       "    Formula: t ~ 1 + (1|participant_id)\n",
       "    Priors:\n",
       "        t_Intercept ~ Normal(mu: 0.0, sigma: 0.25)\n",
       "        t_1|participant_id ~ Normal(mu: 0.0, sigma: Weibull(alpha: 1.5, beta: 0.30000001192092896))\n",
       "    Link: log\n",
       "    Explicit bounds: (0.0, inf)\n",
       " (ignored due to link function)\n",
       "\n",
       "Lapse probability: 0.05\n",
       "Lapse distribution: Uniform(lower: 0.0, upper: 20.0)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_safe_loglogit = hssm.HSSM(\n",
    "    data=cav_data,\n",
    "    global_formula=\"y ~ 1 + (1|participant_id)\",\n",
    "    prior_settings=\"safe\",\n",
    "    link_settings=\"log_logit\",\n",
    ")\n",
    "model_safe_loglogit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762e94e1-66be-47c6-9024-59047790953a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
