{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ecc15b5-726f-4065-a095-26117b8a4f9c",
   "metadata": {},
   "source": [
    "<center> <img src=\"images/HSSM_logo.png\"> </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aaef866",
   "metadata": {},
   "source": [
    "This tutorial provides a comprehensive introduction to the HSSM package for Hierarchical Bayesian Estimation of Sequential Sampling Models.\n",
    "\n",
    "To make the most of the tutorial, let us cover the functionality of the key supporting packages that we use along the way. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b6ce99",
   "metadata": {},
   "source": [
    "## Colab Instructions\n",
    "\n",
    "If you would like to run this tutorial on Google colab, please click this [link](https://github.com/lnccbrown/HSSM/blob/main/docs/tutorials/main_tutorial.ipynb). \n",
    "\n",
    "Once you are *in the colab*, follow the *installation instructions below* and then **restart your runtime**. \n",
    "\n",
    "Just **uncomment the code in the next code cell** and run it!\n",
    "\n",
    "**NOTE**:\n",
    "\n",
    "You may want to *switch your runtime* to have a GPU or TPU. To do so, go to *Runtime* > *Change runtime type* and select the desired hardware accelerator.\n",
    "\n",
    "Note that if you switch your runtime you have to follow the installation instructions again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5fdf6df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If running this on Colab, please uncomment the next line\n",
    "# !pip install git+https://github.com/lnccbrown/HSSM@workshop_tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c58561ef-cd0d-4391-be8c-9975213b4b51",
   "metadata": {},
   "source": [
    "## Basic Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74cd0ee8-3497-44ae-8a89-393d975a65db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "#warnings.filterwarnings(action='once')\n",
    "\n",
    "# Basics\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "random_seed_sim = 134\n",
    "np.random.seed(random_seed_sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88a88ce",
   "metadata": {},
   "source": [
    "## Data Simulation\n",
    "\n",
    "We will rely on the [ssms](https://github.com/AlexanderFengler/ssm-simulators) package for data simulation repeatedly. Let's look at a basic isolated use case below.\n",
    "\n",
    "As an example, let's use [ssms](https://github.com/AlexanderFengler/ssm-simulators) to simulate from the basic [Drift Diffusion Model](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2474742/) (a running example in this tutorial).\n",
    "\n",
    "<center> <img src=\"images/DDM_with_params_pic.png\" height=\"400\" width=\"400\"> </center>\n",
    "\n",
    "If you are not familiar with the DDM. For now just consider that it has four parameters. \n",
    "\n",
    "- `v` the drift rate\n",
    "- `a` the boundary separation\n",
    "- `t` the non-decision time\n",
    "- `z` the a priori decision bias (starting point)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf31635-7e9c-44f8-ac83-0dd71e54eafe",
   "metadata": {},
   "source": [
    "### Using `simulate_data()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "015aa049",
   "metadata": {},
   "source": [
    "HSSM comes with a basic simulator function supplied the `simulate_data()` function. We can use this function to create synthetic datasets.\n",
    "\n",
    "Below we show the most basic usecase: \n",
    "\n",
    "We wish to generate `500` datapoints (trials) from the standard [Drift Diffusion Model](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2474742/) with a fixed parameters, `v = 0.5, a = 1.5, z = 0.5, t = 0.5`. \n",
    "\n",
    "\n",
    "**Note**:\n",
    "\n",
    "In the course of the tutorial, we will see multiple strategies for synthetic dataset generation, this being the most straightforward one. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eeb964f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rt</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.791911</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.094867</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.845557</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.989894</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.683095</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>2.167489</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>1.480039</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>3.552173</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>2.129561</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>1.008422</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           rt  response\n",
       "0    3.791911      -1.0\n",
       "1    1.094867      -1.0\n",
       "2    5.845557       1.0\n",
       "3    0.989894       1.0\n",
       "4    2.683095       1.0\n",
       "..        ...       ...\n",
       "495  2.167489       1.0\n",
       "496  1.480039       1.0\n",
       "497  3.552173      -1.0\n",
       "498  2.129561       1.0\n",
       "499  1.008422       1.0\n",
       "\n",
       "[500 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Single dataset\n",
    "import hddm_wfpt\n",
    "import hssm\n",
    "import pytensor  # Graph-based tensor library\n",
    "import jax\n",
    "import bambi as bmb # Model construction \n",
    "import arviz as az  # Visualization\n",
    "\n",
    "pytensor.config.floatX = \"float32\"\n",
    "jax.config.update(\"jax_enable_x64\", False)\n",
    "\n",
    "v_true = 0.5\n",
    "a_true = 1.5\n",
    "z_true = 0.5\n",
    "t_true = 0.5\n",
    "\n",
    "# Call the simulator function\n",
    "dataset = hssm.simulate_data(model = 'ddm',\n",
    "\t\t\t\t\t\t\t theta = dict(v = v_true,\n",
    "\t\t\t\t\t\t\t\t\t\t  a = a_true,\n",
    "\t\t\t\t\t\t\t\t\t\t  z = z_true,\n",
    "\t\t\t\t\t\t\t\t\t\t  t = t_true),\n",
    "\t\t\t\t\t\t\t size = 500)\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db5e983",
   "metadata": {},
   "source": [
    "If instead you wish to supply a parameter that *varies by trial* (a lot more on this later), you can simply supply a vector of parameters to the `theta` dictionary, when calling the simulator.\n",
    "\n",
    "**Note**:\n",
    "\n",
    "The `size` argument conceptually functions as *number of synthetic datasets*. So if you supply a parameter as a `(1000,)` vector, then the simulator assumes that one dataset consists of `1000` trials, hence if we set the `size = 1` as below, we expect in return a dataset with `1000` trials. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "126783dc-19b7-47e0-95ac-c6314454bb02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rt</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.541487</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.877541</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.633046</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.677460</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.091263</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>3.208477</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>2.262080</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>1.910646</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>2.647852</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>11.750345</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            rt  response\n",
       "0     3.541487       1.0\n",
       "1     1.877541       1.0\n",
       "2     1.633046       1.0\n",
       "3     2.677460       1.0\n",
       "4     3.091263       1.0\n",
       "..         ...       ...\n",
       "995   3.208477       1.0\n",
       "996   2.262080       1.0\n",
       "997   1.910646       1.0\n",
       "998   2.647852       1.0\n",
       "999  11.750345       1.0\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a changes trial wise\n",
    "a_trialwise = np.random.normal(loc=2, scale=0.3, size=1000)\n",
    "\n",
    "dataset_a_trialwise = hssm.simulate_data(model = 'ddm',\n",
    "                                         theta = dict(v = v_true,\n",
    "                                                      a = a_trialwise,\n",
    "                                                      z = z_true, \n",
    "                                                      t = t_true,\n",
    "                                                      ),          \n",
    "                                         size = 1)\n",
    "\n",
    "dataset_a_trialwise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d2787b-8bea-43d3-acb6-53d02c7eabe5",
   "metadata": {},
   "source": [
    "If we wish to simulate from another model, we can do so by changing the `model` string.\n",
    "\n",
    "The number of models we can simulate differs from the number of models for which we have likelihoods available (both will increase over time). To get the models for which likelihood functions are supplied out of the box, we should check the `SupportedModels` under `hssm.defaults`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "641b0d58-a9e4-43b3-9f6a-2a706256cb1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "typing.Literal['ddm', 'ddm_sdv', 'full_ddm', 'angle', 'levy', 'ornstein', 'weibull', 'race_no_bias_angle_4', 'ddm_seq2_no_bias']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hssm.defaults.SupportedModels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43703bd7-f50c-40eb-a130-2070b160a8ec",
   "metadata": {},
   "source": [
    "If we wish to check more detailed information about a given model, we can use the `default_model_config` under `hssm.default`.\n",
    "\n",
    "Let's look at the `ddm`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a526455-37e4-428c-a478-43ef387e496e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'response': ['rt', 'response'],\n",
       " 'list_params': ['v', 'a', 'z', 't', 'theta'],\n",
       " 'description': None,\n",
       " 'likelihoods': {'approx_differentiable': {'loglik': 'angle.onnx',\n",
       "   'backend': 'jax',\n",
       "   'default_priors': {},\n",
       "   'bounds': {'v': (-3.0, 3.0),\n",
       "    'a': (0.3, 3.0),\n",
       "    'z': (0.1, 0.9),\n",
       "    't': (0.001, 2.0),\n",
       "    'theta': (-0.1, 1.3)},\n",
       "   'extra_fields': None}}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hssm.defaults.default_model_config['angle']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02343768-82f3-475b-8c9f-94869b35c7c4",
   "metadata": {},
   "source": [
    "This dictionary contains quite a bit of information. For purposes of *simulating data from a given model*, we will highlight two aspects:\n",
    "\n",
    "1.  The key `list_of_params` provides us with the necessary information to define out `theta` dictionary\n",
    "2.  The `bounds` key inside the `likelihoods` sub-dictionaries, provides us with an indication of reasonable parameter values.\n",
    "\n",
    "The `likelihoods` dictionary inhabits three sub-directories for the `ddm` model, since we have all three, an `analytical`, an `approx_differentiable` (LAN) and a `blackbox` likelihood available. For many models, we will be able to access only one or two types of likelihoods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da49fe22-7e9a-4fb7-919c-d759baf08250",
   "metadata": {},
   "source": [
    "### Using `ssm-simulators`\n",
    "\n",
    "Internally, HSSM natively makes use of the [ssm-simulators](https://github.com/AlexanderFengler/ssm-simulators) package for forward simulation of models. \n",
    "`hssm.simulate_data()` functions essentially as a convenience-wrapper. \n",
    "\n",
    "Below we illustrate how to simulate data using the `ssm-simulators` package directly, to generate an equivalent dataset as created above. We will use the *third* way of passing parameters to the simulator, which is as a parameter-*matrix*. \n",
    "\n",
    "**Notes**:\n",
    "\n",
    "1. If you pass parameters as a parameter matrix, make sure the column ordering is correct. You can follow the parameter ordering under `hssm.defaults.default_model_config['ddm']['list_params']`.\n",
    "\n",
    "2. This is a minimal example, for more information about the package, check the associated [github-page](https://github.com/AlexanderFengler/ssm-simulators). \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e128e932",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mssms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbasic_simulators\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msimulator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m simulator\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# a changes trial wise\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m theta_mat \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;241m1000\u001b[39m, \u001b[38;5;241m4\u001b[39m))\n\u001b[1;32m      7\u001b[0m theta_mat[:, \u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m=\u001b[39m v_true \u001b[38;5;66;03m# v\u001b[39;00m\n\u001b[1;32m      8\u001b[0m theta_mat[:, \u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m a_trialwise \u001b[38;5;66;03m# a\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "import ssms\n",
    "import pandas as pd\n",
    "from ssms.basic_simulators.simulator import simulator\n",
    "\n",
    "# a changes trial wise\n",
    "theta_mat = np.zeros((1000, 4))\n",
    "theta_mat[:, 0] = v_true # v\n",
    "theta_mat[:, 1] = a_trialwise # a\n",
    "theta_mat[:, 2] = z_true # z\n",
    "theta_mat[:, 3] = t_true # t\n",
    "\n",
    "# simulate data\n",
    "sim_out_trialwise = simulator(\n",
    "    theta=theta_mat,  # parameter_matrix\n",
    "    model=\"ddm\",  # specify model (many are included in ssms)\n",
    "    n_samples=1,  # number of samples for each set of parameters (plays the role of `size` parameter in `hssm.simulate_data`)\n",
    ")\n",
    "\n",
    "# Turn into nice dataset\n",
    "dataset_trialwise = pd.DataFrame(\n",
    "    np.column_stack(\n",
    "        [sim_out_trialwise[\"rts\"][:, 0], sim_out_trialwise[\"choices\"][:, 0]]\n",
    "    ),\n",
    "    columns=[\"rt\", \"response\"],\n",
    ")\n",
    "\n",
    "dataset_trialwise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51c6923",
   "metadata": {},
   "source": [
    "We will stick to `hssm.simulate_data()` in this tutorial, to keep things simple."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786303f5",
   "metadata": {},
   "source": [
    "## ArviZ for Plotting\n",
    "\n",
    "<center> <img src=\"images/arviz.png\" height=\"200\" width=\"200\"> </center>\n",
    "\n",
    "\n",
    "We use the [ArviZ](https://python.arviz.org/en/stable/) package for most of our plotting needs. \n",
    "ArviZ is a useful aid for plotting when doing anything Bayesian. \n",
    "\n",
    "It works with HSSM out of the box, by virtue of HSSMs reliance on [PyMC](https://www.pymc.io/welcome.html) for model construction and sampling.\n",
    "\n",
    "Checking out the [ArviZ Documentation](https://python.arviz.org/en/stable/getting_started/index.html) is a good idea to give you communication superpowers for not only your HSSM results, but also other libraries in the Bayesian Toolkit such as [NumPyro](https://num.pyro.ai/en/latest/index.html#introductory-tutorials) or [STAN](https://mc-stan.org/users/documentation/).\n",
    "\n",
    "We will see [ArviZ](https://python.arviz.org/en/stable/) plots throughout the notebook.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcb148a",
   "metadata": {},
   "source": [
    "# Main Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e41269-4c1e-4ec5-b2eb-82c35ee860c2",
   "metadata": {},
   "source": [
    "## Initial Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7aa8a33",
   "metadata": {},
   "source": [
    "Let's proceed to simulate a simple dataset for our first example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "99bd95f4-5775-4142-8d6c-a01bfab7c88e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rt</th>\n",
       "      <th>response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.873666</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.317008</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.017146</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.252344</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.053887</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>1.585201</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>3.210716</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>6.281962</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>1.205276</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0.758284</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           rt  response\n",
       "0    1.873666       1.0\n",
       "1    3.317008       1.0\n",
       "2    2.017146       1.0\n",
       "3    2.252344      -1.0\n",
       "4    1.053887       1.0\n",
       "..        ...       ...\n",
       "495  1.585201       1.0\n",
       "496  3.210716       1.0\n",
       "497  6.281962      -1.0\n",
       "498  1.205276       1.0\n",
       "499  0.758284       1.0\n",
       "\n",
       "[500 rows x 2 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Specify \n",
    "param_dict_init = dict(v = v_true,\n",
    "                       a = a_true,\n",
    "                       z = z_true,\n",
    "                       t = t_true,\n",
    "                      )\n",
    "\n",
    "\n",
    "dataset = hssm.simulate_data(model = 'ddm',\n",
    "                   theta = param_dict_init,          \n",
    "                   size = 500,\n",
    "                   )\n",
    "\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4c6129-ac7c-46d1-928f-96095f97dca6",
   "metadata": {},
   "source": [
    "## First HSSM Model\n",
    "\n",
    "In this example we will use the *analytical likelihood function* computed as suggested in [this paper](https://psycnet.apa.org/record/2009-11068-003)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408d4ac6-0138-493e-81f8-0a7c31edac3a",
   "metadata": {},
   "source": [
    "### Instantiate the model\n",
    "\n",
    "To instantiate our `HSSM` class, in the simplest version, we only need to provide an appropriate dataset.\n",
    "The dataset is expected to be a `pandas.DataFrame` with at least two columns, respectively called `rt` (for reaction time) and `response`.\n",
    "Our data simulated above is already in the correct format, so let us try to construct the class.\n",
    "\n",
    "**NOTE:**\n",
    "\n",
    "If you are a user of the [HDDM](https://github.com/hddm-devs/hddm) python package, this workflow should seem very familiar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bde3e564-56f0-4689-886c-fc6f245c0833",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_ddm_model = hssm.HSSM(data=dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a77ed306",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hierarchical Sequential Sampling Model\n",
       "Model: ddm\n",
       "\n",
       "Response variable: rt,response\n",
       "Likelihood: analytical\n",
       "Observations: 500\n",
       "\n",
       "Parameters:\n",
       "\n",
       "v:\n",
       "    Prior: Normal(mu: 0.0, sigma: 2.0)\n",
       "    Explicit bounds: (-inf, inf)\n",
       "\n",
       "a:\n",
       "    Prior: HalfNormal(sigma: 2.0)\n",
       "    Explicit bounds: (0.0, inf)\n",
       "\n",
       "z:\n",
       "    Prior: Uniform(lower: 0.0, upper: 1.0)\n",
       "    Explicit bounds: (0.0, 1.0)\n",
       "\n",
       "t:\n",
       "    Prior: HalfNormal(sigma: 2.0)\n",
       "    Explicit bounds: (0.0, inf)\n",
       "\n",
       "\n",
       "Lapse probability: 0.05\n",
       "Lapse distribution: Uniform(lower: 0.0, upper: 10.0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_ddm_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38905d9",
   "metadata": {},
   "source": [
    "The `print()` function gives us some basic information about our model including the *number of observations* the *parameters in the model* and their respective *prior setting*. We can also create a nice little graphical representation of our model..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697137e0",
   "metadata": {},
   "source": [
    "### Model Graph\n",
    "\n",
    "Since `HSSM` creates a `PyMC Model`, we can can use the `.graph()` function, to get a graphical representation of the the model we created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "caab1cee-92b9-4851-8be0-b26911046b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hssm.utils import HSSMModelGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9323904a-ec43-4e48-b557-ff5e9bc00909",
   "metadata": {},
   "outputs": [],
   "source": [
    "ModelGraph = HSSMModelGraph(model=simple_ddm_model.pymc_model, parent=simple_ddm_model._parent_param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b4196725-373a-4108-92eb-0f8a3756a42a",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable Plate object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m a, b \u001b[38;5;129;01min\u001b[39;00m ModelGraph\u001b[38;5;241m.\u001b[39mget_plates([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mv\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m]):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(a)\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;28mprint\u001b[39m(b)\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable Plate object"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba2e8b97-608e-4511-a169-ead1ee1330a6",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mModelGraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mplain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_str\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msimple_ddm_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse_str\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-Personal/proj_hssm/HSSM/src/hssm/utils.py:205\u001b[0m, in \u001b[0;36mHSSMModelGraph.make_graph\u001b[0;34m(self, var_names, formatting, response_str)\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    204\u001b[0m graph \u001b[38;5;241m=\u001b[39m graphviz\u001b[38;5;241m.\u001b[39mDigraph(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m--> 205\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m plate_label, all_var_names \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_plates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar_names\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m():\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m plate_label:\n\u001b[1;32m    207\u001b[0m         \u001b[38;5;66;03m# must be preceded by 'cluster' to get a box around it\u001b[39;00m\n\u001b[1;32m    208\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m graph\u001b[38;5;241m.\u001b[39msubgraph(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m plate_label) \u001b[38;5;28;01mas\u001b[39;00m sub:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "ModelGraph.make_graph(formatting='plain', response_str=simple_ddm_model.response_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52d254c6-7145-46af-a546-180cc2974a9a",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43msimple_ddm_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgraph\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-Personal/proj_hssm/HSSM/src/hssm/hssm.py:930\u001b[0m, in \u001b[0;36mHSSM.graph\u001b[0;34m(self, formatting, name, figsize, dpi, fmt)\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Produce a graphviz Digraph from a built HSSM model.\u001b[39;00m\n\u001b[1;32m    891\u001b[0m \n\u001b[1;32m    892\u001b[0m \u001b[38;5;124;03mRequires graphviz, which may be installed most easily with `conda install -c\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    924\u001b[0m \u001b[38;5;124;03m    Credit for the code goes to Bambi developers.\u001b[39;00m\n\u001b[1;32m    925\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    926\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39m_check_built()\n\u001b[1;32m    928\u001b[0m graphviz \u001b[38;5;241m=\u001b[39m \u001b[43mHSSMModelGraph\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    929\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpymc_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_param\u001b[49m\n\u001b[0;32m--> 930\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformatting\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_str\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse_str\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    932\u001b[0m width, height \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;28;01mif\u001b[39;00m figsize \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m figsize\n\u001b[1;32m    934\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/CloudStorage/OneDrive-Personal/proj_hssm/HSSM/src/hssm/utils.py:205\u001b[0m, in \u001b[0;36mHSSMModelGraph.make_graph\u001b[0;34m(self, var_names, formatting, response_str)\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    204\u001b[0m graph \u001b[38;5;241m=\u001b[39m graphviz\u001b[38;5;241m.\u001b[39mDigraph(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m--> 205\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m plate_label, all_var_names \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_plates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar_names\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m():\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m plate_label:\n\u001b[1;32m    207\u001b[0m         \u001b[38;5;66;03m# must be preceded by 'cluster' to get a box around it\u001b[39;00m\n\u001b[1;32m    208\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m graph\u001b[38;5;241m.\u001b[39msubgraph(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcluster\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m plate_label) \u001b[38;5;28;01mas\u001b[39;00m sub:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "simple_ddm_model.graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88deda4",
   "metadata": {},
   "source": [
    "This is the simplest model we can build. The graph above follows **plate notation**, commonly used for **probabilistic graphical models**.\n",
    "\n",
    "- We have our basic parameters (unobserved, **white nodes**), these are *random variables* in the model and we want to estimate them\n",
    "- Our observed reaction times and choices (`SSMRandomVariable`, **grey node**), are fixed (or conditioned on).\n",
    "- **Rounded rectangles** provide us with information about dimensionality of objects\n",
    "- **Rectangles with sharp edges** represent *deterministic*, but *computed* quantities (not shown here, but in later models)\n",
    "\n",
    "This notation is helpful to get a quick overview of the structure of a given model we construct.\n",
    "\n",
    "The `graph()` function of course becomes a lot more interesting and useful for more complicated models!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705cf547",
   "metadata": {},
   "source": [
    "### Sample from the Model\n",
    "\n",
    "We can now call the `.sample()` function, to get posterior samples. The main arguments you may want to change are listed in the function call below. \n",
    "\n",
    "Importantly, multiple backends are possible. We choose the `nuts_numpyro` backend below,\n",
    "which in turn compiles the model to a [`JAX`](https://github.com/google/jax) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de5037b-cb2c-4d0e-a5e3-5ede4006e50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_data_simple_ddm_model = simple_ddm_model.sample(\n",
    "    sampler=\"nuts_numpyro\",  # type of sampler to choose, 'nuts_numpyro', 'nuts_blackjax' of default pymc nuts sampler\n",
    "    cores=1,  # how many cores to use\n",
    "    chains=2,  # how many chains to run\n",
    "    draws=500,  # number of draws from the markov chain\n",
    "    tune=1000,  # number of burn-in samples\n",
    "    idata_kwargs=dict(log_likelihood=True),  # return log likelihood\n",
    ")  # mp_ctx=\"forkserver\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c9fb68-2e7d-4d8b-9828-568e7a330015",
   "metadata": {},
   "source": [
    "We sampled from the model, let's look at the output..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60244a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(infer_data_simple_ddm_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9b00c7",
   "metadata": {},
   "source": [
    "Errr... a closer look might be needed here!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "536bd280",
   "metadata": {},
   "source": [
    "### Inference Data / What gets returned from the sampler?\n",
    "\n",
    "The sampler returns an [ArviZ](https://python.arviz.org/en/stable/) `InferenceData` object. \n",
    "\n",
    "To understand all the logic behind these objects and how they mesh with the Bayesian Workflow, we refer you to the [ArviZ Documentation](https://python.arviz.org/en/stable/getting_started/index.html). \n",
    "\n",
    "`InferenceData` is build on top of [xarrays](https://docs.xarray.dev/en/stable/index.html). The [xarray documentation](https://docs.xarray.dev/en/stable/index.html) will help you understand in more detail how to manipulate these objects.\n",
    "\n",
    "But let's take a quick high-level look to understand roughly what we are dealing with here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00997d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_data_simple_ddm_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3cf6d6",
   "metadata": {},
   "source": [
    "We see that in our case, `infer_data_simple_ddm_model` contains four basic types of data (note: this is extensible!)\n",
    "\n",
    "- `posterior`\n",
    "- `log_likelihood`\n",
    "- `sample_stats`\n",
    "- `observed_data`\n",
    "\n",
    "The `posterior` object contains our traces for each of the parameters in the model. The `log_likelihood` field contains the trial wise log-likelihoods for each sample from the posterior. The `sample_stats` field contains information about the sampler run. This can be important for chain diagnostics, but we will not dwell on this here. Finally we retreive our `observed_data`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9882230-0c70-45dc-8313-dd60385f20cc",
   "metadata": {},
   "source": [
    "### Basic Manipulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb86e16e-abb3-4b48-bf27-ec0559a8759d",
   "metadata": {},
   "source": [
    "#### Accessing groups and variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b11a7a4-cebc-4860-bec5-120683d1d893",
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_data_simple_ddm_model.posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b9f0a6e-2055-40f1-8d78-2160eba2862e",
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_data_simple_ddm_model.posterior.a.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91fff235-0325-4f54-9445-1981e4c099c5",
   "metadata": {},
   "source": [
    "To simply access the underlying data as a `numpy.ndarray`, we can use `.values` (as e.g. when using `pandas.DataFrame` objects). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb441487-55ce-46ef-9864-47cc011a07d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(infer_data_simple_ddm_model.posterior.a.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a562f58-0792-450a-800b-8243268cf21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#infer_data_simple_ddm_model.posterior.a.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b987685-6b8c-4542-8e5f-a52a0e6bc3a4",
   "metadata": {},
   "source": [
    "#### Combine `chain` and `draw` dimension\n",
    "\n",
    "When operating directly on the `xarray`, you will often find it useful to collapse the `chain` and `draw` coordinates into a single coordinate.\n",
    "**Arviz** makes this easy via the `extract` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9c761e-25d0-4157-a9e6-7d54148111ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "idata_extracted = az.extract(infer_data_simple_ddm_model)\n",
    "idata_extracted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a010409-b68f-455d-a2ba-abbc88e47f01",
   "metadata": {},
   "source": [
    "Since *Arviz* really just calls the `.stack()` method from *xarray*, here the corresponding example using the lower level `xarray` interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7ddb40-15fd-4231-80a6-fab9e3d1513f",
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_data_simple_ddm_model.posterior.stack(sample=('chain', 'draw'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f12b46",
   "metadata": {},
   "source": [
    "### Making use of ArviZ\n",
    "\n",
    "Working with the `InferenceData` directly, is very helpful if you want to include custom computations into your workflow. \n",
    "For a basic Bayesian Workflow however, you will often find that standard functionality available through [ArviZ](https://python.arviz.org/en/stable/)\n",
    "suffices.\n",
    "\n",
    "Below we provide a few examples of useful **Arviz** outputs, which come handy for analyzing your traces (MCMC samples).\n",
    "\n",
    "#### Summary table\n",
    "\n",
    "Let's take a look at a summary table for our posterior. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9a4921",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(infer_data_simple_ddm_model, \n",
    "           var_names = [var_name.name for var_name in simple_ddm_model.pymc_model.free_RVs])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43bc795",
   "metadata": {},
   "source": [
    "This table returns the parameter-wise mean of our posterior and a few extra statistics.\n",
    "\n",
    "Of these extra statistics, the one-stop shop for flagging convergence issues is the `r_hat` value, which \n",
    "is reported in the right-most column. \n",
    "\n",
    "To navigate this statistic, here is a rule of thumb widely used in applied Bayesian statistics.\n",
    "\n",
    "If you find an `r_hat` value `> 1.01`, it warrants investigation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "990d9097",
   "metadata": {},
   "source": [
    "#### Trace plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a25b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(\n",
    "    infer_data_simple_ddm_model,  # we exclude the log_likelihood traces here\n",
    "    lines = [(key_, {}, param_dict_init[key_]) for key_ in param_dict_init],\n",
    ")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775ab0cb",
   "metadata": {},
   "source": [
    "The `.sample()` function also sets a `trace` attribute, on our `hssm` class, so instead, we could call the plot like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c018d083-d5fb-4a9d-9f89-583a97592dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(simple_ddm_model.traces,\n",
    "              lines = [(key_, {}, param_dict_init[key_]) for key_ in param_dict_init],\n",
    "             );"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0874ffb3",
   "metadata": {},
   "source": [
    "In this tutorial we are most often going to use the latter way of accessing the traces, but there is no preferred option. \n",
    "\n",
    "Let's look at a few more plots."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6bebfa8",
   "metadata": {},
   "source": [
    "#### Forest Plot\n",
    "\n",
    "The forest plot is commonly used for a quick visual check of the marginal posteriors. It is very effective for intuitive communication of results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de8f8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_forest(simple_ddm_model.traces)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963b1690-52e9-4fdf-83e2-8afdf556ca97",
   "metadata": {},
   "source": [
    "##### Combining Chains\n",
    "By default, chains are separated out into *separate caterpillars*, however\n",
    "sometimes, especially if you are looking at a forest plot which includes many posterior parameters at once, you want to declutter and collapse the chains into single caterpillars.\n",
    "In this case you can `combine` chains instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d0449c-2f7c-48e0-8eac-924eb6769c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_forest(simple_ddm_model.traces, combined=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bda8b3",
   "metadata": {},
   "source": [
    "#### Basic Marginal Posterior Plot\n",
    "\n",
    "Another way to view the marginal posteriors is provided by the `plot_posterior()` function. It shows the mean and by default the $94\\%$ HDIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8293e79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_posterior(simple_ddm_model.traces)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3ad079-feb2-4a83-9585-83edae1883a5",
   "metadata": {},
   "source": [
    "Especially for parameter recovery studies, you may want to include **reference values** for the parameters of interest. \n",
    "\n",
    "You can do so using the `ref_val` argument. See the example below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0742e83-3523-484d-a960-d08a0a9312eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_posterior(simple_ddm_model.traces, \n",
    "                  ref_val = [param_dict_init[var_name] for var_name in simple_ddm_model.traces.posterior.data_vars])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f705e9b-13c5-4d2f-9fd9-1ccbbced8364",
   "metadata": {},
   "source": [
    "Since it is sometimes useful, especially for more complex cases, below an alternative approach in which we pass `ref_val` as a dictionary.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23397920-5ffa-4a58-b477-7f76b0682452",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_posterior(simple_ddm_model.traces, ref_val = {'v': [{'ref_val': param_dict_init['v']}],\n",
    "                                                      'a': [{'ref_val': param_dict_init['a']}],\n",
    "                                                      'z': [{'ref_val': param_dict_init['z']}],\n",
    "                                                      't': [{'ref_val': param_dict_init['t']}]})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f7bde4",
   "metadata": {},
   "source": [
    "#### Posterior Pair Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec85e32b",
   "metadata": {},
   "source": [
    "The posterior pair plot show us bi-variate traceplots and is useful to check for simple parameter tradeoffs that may emerge. The simplest (linear) tradeoff may be a high correlation between two parameters.\n",
    "This can be very helpful in diagnosing sampler issues for example. If such tradeoffs exist, one often see extremely *wide marginal distributions*.\n",
    "\n",
    "In our `ddm` example, we see a little bit of a tradeoff between `a` and `t`, as well as between `v` and `z`, however nothing concerning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc4b3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_pair(simple_ddm_model.traces, \n",
    "             kind=\"kde\", \n",
    "             reference_values = param_dict_init, \n",
    "             marginals = True);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50101465",
   "metadata": {},
   "source": [
    "The few plot we showed here are just the beginning: [ArviZ](https://python.arviz.org/en/stable/) has a much broader spectrum of graphs and other convenience function available. Just check the [documentation](https://python.arviz.org/en/stable/). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8ae160-3849-498d-b0bb-86d9e3ea5ea9",
   "metadata": {},
   "source": [
    "### Compute Quantities from idata\n",
    "\n",
    "#### Example: Mean and Covariance of Posterior Parameters\n",
    "\n",
    "As a simple example, let us calculate the covariance matrix for our posterior samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bcbeebb-821e-4af3-8fcc-e97e5a609aba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the correlation matrix\n",
    "posterior_correlation_matrix = np.corrcoef(np.stack([idata_extracted[var_].values for var_ in idata_extracted.data_vars.variables]))\n",
    "num_vars = posterior_correlation_matrix.shape[0]\n",
    "\n",
    "# Make heatmap\n",
    "fig, ax = plt.subplots(1,1)\n",
    "cax = ax.imshow(posterior_correlation_matrix, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "fig.colorbar(cax, ax=ax)\n",
    "ax.set_title(\"Posterior Correlation Matrix\")\n",
    "\n",
    "# Add ticks\n",
    "ax.set_xticks(range(posterior_correlation_matrix.shape[0]))\n",
    "ax.set_xticklabels([var_ for var_ in idata_extracted.data_vars.variables])\n",
    "ax.set_yticks(range(posterior_correlation_matrix.shape[0]))\n",
    "ax.set_yticklabels([var_ for var_ in idata_extracted.data_vars.variables])\n",
    "\n",
    "# Annotate heatmap\n",
    "for i in range(num_vars):\n",
    "    for j in range(num_vars):\n",
    "        ax.text(j, i, f'{posterior_correlation_matrix[i, j]:.2f}', ha='center', va='center', color='black')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfe0244-7d58-452d-9b32-7a9e9bb77b9b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## HSSM Model based on LAN likelihood\n",
    "\n",
    "With HSSM you can switch between pre-supplied models with a simple change of argument. The type of likelihood that will be accessed might change in the background for you. \n",
    "\n",
    "Here we see an example in which the underlying likelihood is now a [LAN](https://elifesciences.org/articles/65074).\n",
    "\n",
    "We will talk more about different types of likelihood functions and backends later in the tutorial. For now just keep the following in mind:\n",
    "\n",
    "There are three types of likelihoods\n",
    "\n",
    "1. `analytic`\n",
    "2. `approx_differentiable`\n",
    "3. `blackbox`\n",
    "\n",
    "To check which type is used in your HSSM model simple type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18164585",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_ddm_model.loglik_kind"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b65972",
   "metadata": {},
   "source": [
    "Ah... we were using an `analytical` likelihood with the DDM model in the last section.\n",
    "Now let's see something different!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe18bea-b7f4-4542-8293-7374f81c670e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Simulating Angle Data\n",
    "\n",
    "Again, let us simulate a simple dataset. This time we will use the `angle` model (passed via the `model` argument to the `simulator()` function). \n",
    "\n",
    "\n",
    "This model is distinguished from the basic `ddm` model by an additional `theta` parameter which specifies the angle with which the decision boundaries collapse over time.\n",
    "\n",
    "<center> <img src=\"images/ANGLE_with_params_pic.png\" height=\"400\" width=\"400\"> </center>\n",
    "\n",
    "DDMs with collapsing bounds have been of significant interest in the theoretical literature, but applications were rare due to a lack of analytical likelihoods. HSSM facilitates inference with such models via the our `approx_differentiable` likelihoods. HSSM ships with a few predefined models based on [LANs](https://elifesciences.org/articles/65074), but really we don't want to overemphasize those. They reflect the research interest of our and adjacent labs to a great extend. \n",
    "\n",
    "Instead, we encourage the community to contribute to this model reservoir (more on this later). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ce0b9a-f47b-40ff-96fd-85abb7cbeb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate angle data\n",
    "v_angle_true = 0.5\n",
    "a_angle_true = 1.5\n",
    "z_angle_true = 0.5\n",
    "t_angle_true = 0.2\n",
    "theta_angle_true = 0.2\n",
    "\n",
    "param_dict_angle = dict(v = 0.5, \n",
    "                        a = 1.5, \n",
    "                        z = 0.5,\n",
    "                        t = 0.2,\n",
    "                        theta = 0.2)\n",
    "\n",
    "lines_list_angle = [(key_, {}, param_dict_angle[key_]) for key_ in param_dict_angle]\n",
    "\n",
    "dataset_angle = hssm.simulate_data(model = 'angle',\n",
    "                                   theta = param_dict_angle,\n",
    "                                   size = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a67a27",
   "metadata": {},
   "source": [
    "We pass a single additional argument to our `HSSM` class and set `model='angle'`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2ff936",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_angle = hssm.HSSM(data=dataset_angle, model=\"angle\")\n",
    "\n",
    "model_angle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223b91f2-ffd4-473f-a93f-5ea266c703a4",
   "metadata": {},
   "source": [
    "The model graph now show us an additional parameter `theta`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116bc47f-dd87-4857-ae5a-d480fae6e3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_angle.graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b92ed46d",
   "metadata": {},
   "source": [
    "Let's check the type of likelihood that is used under the hood ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8632654",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_angle.loglik_kind"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953bae6c",
   "metadata": {},
   "source": [
    "Ok so here we rely on a likelihood of the `approx_differentiable` kind. \n",
    "\n",
    "As discussed, with the initial set of pre-supplied likelihoods, this implies that we are using a [LAN](https://elifesciences.org/articles/65074) in the background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4325015-1aec-4791-9be6-800d3e60ed4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "jax.config.update(\"jax_enable_x64\", False)\n",
    "infer_data_angle = model_angle.sample(\n",
    "    sampler=\"nuts_numpyro\",\n",
    "    chains=2,\n",
    "    cores=2,\n",
    "    draws=500,\n",
    "    tune=500,\n",
    "    idata_kwargs=dict(log_likelihood=False),  # no need to return likelihoods here\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220f57bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(model_angle.traces, lines = lines_list_angle)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e80ed0",
   "metadata": {},
   "source": [
    "## Choosing Priors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f238e8",
   "metadata": {},
   "source": [
    "HSSM allows you to specify priors quite freely. If you used HDDM previously, you may feel relieved to read that your hands are now untied!\n",
    "\n",
    "\n",
    "<center><img src=\"https://media.giphy.com/media/99uUPYHtmaJS8/giphy.gif\" style=\"margin:auto\" height=\"400\" width=\"400\"/></center>\n",
    "\n",
    "With HSSM we have multiple routes to priors. But let's first consider a special case:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d848f3a",
   "metadata": {},
   "source": [
    "### Fixing a parameter to a given value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48047eb9",
   "metadata": {},
   "source": [
    "Assume that instead of fitting all parameters of the DDM, \n",
    "\n",
    "<center> <img src=\"images/DDM_with_params_pic.png\" height=\"400\" width=\"400\"> </center> \n",
    "\n",
    "we instead want to fit only the `v` (drift) parameter, setting all other parameters to fixed scalar values.\n",
    "\n",
    "<center> <img src=\"images/DDM_only_v_pic.png\" height=\"400\" width=\"400\"> </center> \n",
    "\n",
    "HSSM makes this extremely easy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80ea399-9cd1-45e7-8396-24caee81836c",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dict_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485902c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddm_model_only_v = hssm.HSSM(data=dataset, model=\"ddm\", \n",
    "                             a = param_dict_init['a'], \n",
    "                             t = param_dict_init['t'], \n",
    "                             z = param_dict_init['z'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992f01d9-ad53-4842-923b-01539ba9a6ee",
   "metadata": {},
   "source": [
    "Since we fix all but one parameter, we therefore estimate only one parameter. This should be reflected in our model graph, where we expect only one free random variable `v`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06f17c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddm_model_only_v.graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2f9cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddm_model_only_v.sample(\n",
    "    sampler=\"nuts_numpyro\",\n",
    "    chains=2,\n",
    "    cores=2,\n",
    "    draws=500,\n",
    "    tune=500,\n",
    "    idata_kwargs=dict(log_likelihood=False),  # no need to return likelihoods here\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c18b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(ddm_model_only_v.traces.posterior, lines = [('v', {}, param_dict_init['v'])]);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73509626-8ec2-4034-a8ab-1fe8453990f6",
   "metadata": {},
   "source": [
    "Instead of the trace on the right, a useful alternative / complement is the **rank plot**.\n",
    "As a rule of thumb, if the rank plots within chains look *uniformly distributed*, then our chains generally exhibit *good mixing*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d87827b-07c5-4210-97ad-dd297c519610",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(ddm_model_only_v.traces, kind = 'rank_bars')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd48a34f",
   "metadata": {},
   "source": [
    "### Named priors\n",
    "\n",
    "We can choose any [PyMC](https://www.pymc.io/welcome.html) `Distribution` to specify a prior for a given parameter. \n",
    "\n",
    "Even better, if natural *parameter bounds* are provided, HSSM *automatically truncates the prior distribution* so that it respect these bounds. \n",
    "\n",
    "Below is an example in which we specify a *Normal* prior on the `v` parameter of the DDM. \n",
    "\n",
    "We choose a *ridiculously low* $\\sigma$ value, to illustrate it's regularizing effect on the parameter (just so we see a difference and you are convinced that something changed). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8cd052",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_normal = hssm.HSSM(\n",
    "    data=dataset,\n",
    "    include=[\n",
    "        {\n",
    "            \"name\": \"v\",\n",
    "            \"prior\": {\"name\": \"Normal\", \"mu\": 0, \"sigma\": 0.01},\n",
    "        }\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b135a951",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cdad7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_data_normal = model_normal.sample(\n",
    "    sampler=\"nuts_numpyro\",\n",
    "    chains=2,\n",
    "    cores=2,\n",
    "    draws=500,\n",
    "    tune=500,\n",
    "    idata_kwargs=dict(log_likelihood=False),  # no need to return likelihoods here\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297f13f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(model_normal.traces, \n",
    "              lines = [(key_, {}, param_dict_init[key_]) for key_ in param_dict_init])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43325aad",
   "metadata": {},
   "source": [
    "Observe how we reused our previous dataset with underlying parameters \n",
    "\n",
    "- `v = 0.5`\n",
    "- `a = 1.5`\n",
    "- `z = 0.5`\n",
    "- `t = 0.2`\n",
    "\n",
    "In contrast to our previous sampler round, in which we used Uniform priors, here the `v` estimate is shrunk severley towared $0$ and the `t` and `z` parameter estimates are very biased to make up for this distortion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e5ef71-c461-4b93-8e41-278f89ddb38d",
   "metadata": {},
   "source": [
    "## HSSM Model with Regression\n",
    "\n",
    "\n",
    "<center> <img src=\"images/bambi.png\" height=\"200\" width=\"200\"> </center>\n",
    "\n",
    "Crucial to the scope of HSSM is the ability to link parameters with trial-by-trial covariates via (hierarchical, but more on this later) general linear models. \n",
    " \n",
    "In this section we explore how HSSM deals with these models. No big surprise here... it's simple!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc351b5-50dc-4bfa-8ab7-790162574d30",
   "metadata": {},
   "source": [
    "### Case 1: One parameter is a Regression Target "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b482ac3",
   "metadata": {},
   "source": [
    "#### Simulating Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b59d64",
   "metadata": {},
   "source": [
    "Let's first simulate some data, where the trial-by-trial parameters of the `v` parameter in our model are driven by a simple linear regression model.\n",
    "\n",
    "\n",
    "The regression model is driven by two (random) covariates `x` and `y`, respectively with coefficients of $0.8$ and $0.3$ which are also simulated below.\n",
    "We set the intercept to $0.3$.\n",
    "\n",
    "The rest of the parameters are fixed to single values as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df5b0c8-e724-4cee-8b0e-dd3fb68cfd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up trial by trial parameters\n",
    "v_intercept = 0.3\n",
    "x = np.random.uniform(-1, 1, size=1000)\n",
    "v_x = 0.8\n",
    "y = np.random.uniform(-1, 1, size=1000)\n",
    "v_y = 0.3\n",
    "v_reg_v = v_intercept + (v_x * x) + (v_y * y)\n",
    "\n",
    "# rest\n",
    "a_reg_v = 1.5\n",
    "z_reg_v = 0.5\n",
    "t_reg_v = 0.1\n",
    "\n",
    "param_dict_reg_v = dict(a = 1.5,\n",
    "                        z = 0.5,\n",
    "                        t = 0.1,\n",
    "                        v = v_reg_v,\n",
    "                        v_x = v_x,\n",
    "                        v_y = v_y,\n",
    "                        v_Intercept = v_intercept,\n",
    "                        theta = 0.0)\n",
    "\n",
    "# base dataset\n",
    "dataset_reg_v = hssm.simulate_data(model = 'ddm',\n",
    "                                   theta = param_dict_reg_v,\n",
    "                                   size = 1)\n",
    "\n",
    "# Adding covariates into the datsaframe\n",
    "dataset_reg_v['x'] = x\n",
    "dataset_reg_v['y'] = y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84e3d5a4-f709-421f-a935-5867974ab56a",
   "metadata": {},
   "source": [
    "#### Basic Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813fd418",
   "metadata": {},
   "source": [
    "We now create the `HSSM` model. \n",
    "\n",
    "Notice how we set the `include` argument. The include argument expects a list of dictionaries, one dictionary for each parameter to be specified via a regression model. \n",
    "\n",
    "Four `keys` are expected to be set:\n",
    "\n",
    "- The `name` of the parameter, \n",
    "- Potentially a `prior` for each of the regression level parameters ($\\beta$'s), \n",
    "- The regression `formula` \n",
    "- A `link` function. \n",
    "\n",
    "The regression formula follows the syntax in the [formulae](https://pypi.org/project/formulae/) python package (as used by the [Bambi](https://bambinos.github.io/bambi/) package for building Bayesian Hierarchical Regression Models. \n",
    "\n",
    "[Bambi](https://bambinos.github.io/bambi/) forms the main model-construction backend of HSSM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9059f045-ab0a-4a98-aa85-4e82cde214be",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_reg_v_simple = hssm.HSSM(\n",
    "    data = dataset_reg_v,\n",
    "    include = [{\"name\": \"v\",\n",
    "                \"formula\": \"v ~ 1 + x + y\"}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccd9f3d-b421-4a39-8f84-a98a46b4c368",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_reg_v_simple"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6764041c-1cf3-4157-be42-6682926ca316",
   "metadata": {},
   "source": [
    "##### `Param` class\n",
    "As illustrated below, there is an alternative way of specifying the parameter specific data via the `Param` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a62a18-3c22-458d-b0e5-5eda63d70a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_reg_v_simple_new = hssm.HSSM(\n",
    "    data = dataset_reg_v,\n",
    "    include = [hssm.Param(name = 'v', formula='v ~ 1 + x + y')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3001d5e-299f-4f9a-8259-4585c51e809a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_reg_v_simple_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa68d94-ee27-4843-bb5b-f397d1730cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_reg_v_simple.graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9ec90c-9ea5-44e4-b314-f3a91784c353",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_reg_v_simple)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c3d8992-5764-4d27-bf28-d366f90084d3",
   "metadata": {},
   "source": [
    "#### Custom Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5758263c-03ba-4f0a-bb2c-d8fb60a28ba2",
   "metadata": {},
   "source": [
    "These were the defaults, with a little extra labor, we can e.g. customize the choice of priors for each parameter in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c05579-67e8-45e8-99eb-b693b9fda79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_reg_v = hssm.HSSM(\n",
    "    data=dataset_reg_v,\n",
    "    include=[\n",
    "        {\n",
    "            \"name\": \"v\",\n",
    "            \"prior\": {\n",
    "                \"Intercept\": {\"name\": \"Uniform\", \"lower\": -3.0, \"upper\": 3.0},\n",
    "                \"x\": {\"name\": \"Uniform\", \"lower\": -1.0, \"upper\": 1.0},\n",
    "                \"y\": {\"name\": \"Uniform\", \"lower\": -1.0, \"upper\": 1.0},\n",
    "            },\n",
    "            \"formula\": \"v ~ 1 + x + y\",\n",
    "            \"link\": \"identity\",\n",
    "        }\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ea5591",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_reg_v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8373cb",
   "metadata": {},
   "source": [
    "Notice how `v` is now set as a regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9030902-6d91-4722-b4f6-4237e5763103",
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_data_reg_v = model_reg_v.sample(\n",
    "    sampler=\"nuts_numpyro\", chains=1, cores=1, draws=500, tune=500\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b064d8-150c-4b63-a327-bddf512d1220",
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_data_reg_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5727d1-21b0-4480-b4d3-6b8a8e1799be",
   "metadata": {},
   "outputs": [],
   "source": [
    "#az.plot_forest(model_reg_v.traces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b565449b-48d4-4167-9e77-65907098a956",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(model_reg_v.traces, \n",
    "              var_names = ['~v'],\n",
    "              lines = [(key_, {}, param_dict_reg_v[key_]) for key_ in param_dict_reg_v])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5fb2d4-19db-45e0-9fa8-ed6c8a80a979",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(model_reg_v.traces, \n",
    "              var_names = ['~v'],\n",
    "              lines = [(key_, {}, param_dict_reg_v[key_]) for key_ in param_dict_reg_v])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3ddcec-c2ff-4560-90a8-272c4b113ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looks like parameter recovery was successful\n",
    "az.summary(model_reg_v.traces, var_names = ['~v'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0873bdde",
   "metadata": {},
   "source": [
    "### Case 2: One parameter is a Regression (LAN)\n",
    "\n",
    "We can do the same thing with the `angle` model.\n",
    "\n",
    "**Note**: \n",
    "\n",
    "Our dataset was generated from the basic DDM here, so since the DDM assumes stable bounds, we expect the `theta` (angle of linear collapse) parameter to be recovered as close to $0$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d026f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_reg_v_angle = hssm.HSSM(\n",
    "    data=dataset_reg_v,\n",
    "    model=\"angle\",\n",
    "    include=[\n",
    "        {\n",
    "            \"name\": \"v\",\n",
    "            \"prior\": {\n",
    "                \"Intercept\": {\n",
    "                    \"name\": \"Uniform\",\n",
    "                    \"lower\": -3.0,\n",
    "                    \"upper\": 3.0,\n",
    "                    # \"initval\": 0   # optional --> set the initial value of the parameter (to e.g. avoid boundary violations at the intial sampling step)\n",
    "                },\n",
    "                \"x\": {\n",
    "                    \"name\": \"Uniform\",\n",
    "                    \"lower\": -1.0,\n",
    "                    \"upper\": 1.0,\n",
    "                },\n",
    "                \"y\": {\"name\": \"Uniform\", \"lower\": -1.0, \"upper\": 1.0},\n",
    "            },\n",
    "            \"formula\": \"v ~ 1 + x + y\",\n",
    "            \"link\": \"identity\",\n",
    "        }\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ef6468",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_reg_v_angle.graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c33a21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_reg_v_angle = model_reg_v_angle.sample(\n",
    "    sampler=\"nuts_numpyro\", chains=1, cores=1, draws=1000, tune=500\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999f633c",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(model_reg_v_angle.traces, \n",
    "              var_names = ['~v'],\n",
    "              lines = [(key_, {}, param_dict_reg_v[key_]) for key_ in param_dict_reg_v])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5a82d9",
   "metadata": {},
   "source": [
    "Great! `theta` is recovered correctly, on top of that, we have reasonable recovery for all other parameters!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e815f1b4-34fb-4cf1-b59c-408f2b36aef9",
   "metadata": {},
   "source": [
    "### Case 3: Multiple Parameters are Regression Targets (LAN) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d4191e7",
   "metadata": {},
   "source": [
    "Let's get a bit more ambitious. We may, for example, want to try a regression on a few of our basic model parameters at once. Below we show an example where we model both the `a` and the `v` parameters with a regression.\n",
    "\n",
    "**NOTE:**\n",
    "\n",
    "In our dataset of this section, only `v` is *actually* driven by a trial-by-trial regression, so we expect the regression coefficients for `a` to hover around $0$ in our posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20835d7-3bd7-4516-8ccd-acd0c467fad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate our hssm model\n",
    "from copy import deepcopy\n",
    "param_dict_reg_v_a = deepcopy(param_dict_reg_v)\n",
    "param_dict_reg_v_a['a_Intercept'] = param_dict_reg_v_a['a']\n",
    "param_dict_reg_v_a['a_x'] = 0\n",
    "param_dict_reg_v_a['a_y'] = 0\n",
    "\n",
    "hssm_reg_v_a_angle = hssm.HSSM(\n",
    "    data=dataset_reg_v,\n",
    "    model=\"angle\",\n",
    "    include=[\n",
    "        {\n",
    "            \"name\": \"v\",\n",
    "            \"prior\": {\n",
    "                \"Intercept\": {\"name\": \"Uniform\", \"lower\": -3.0, \"upper\": 3.0},\n",
    "                \"x\": {\"name\": \"Uniform\", \"lower\": -1.0, \"upper\": 1.0},\n",
    "                \"y\": {\"name\": \"Uniform\", \"lower\": -1.0, \"upper\": 1.0},\n",
    "            },\n",
    "            \"formula\": \"v ~ 1 + x + y\",\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"a\",\n",
    "            \"prior\": {\n",
    "                \"Intercept\": {\"name\": \"Uniform\", \"lower\": 0.5, \"upper\": 3.0},\n",
    "                \"x\": {\"name\": \"Uniform\", \"lower\": -1.0, \"upper\": 1.0},\n",
    "                \"y\": {\"name\": \"Uniform\", \"lower\": -1.0, \"upper\": 1.0},\n",
    "            },\n",
    "            \"formula\": \"a ~ 1 + x + y\",\n",
    "        },\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f8d657-96dd-4884-a17d-d25cdbcb14c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "hssm_reg_v_a_angle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3ddf2f-81c0-43e7-b341-747c70db312a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hssm_reg_v_a_angle.graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85a8c55-ee52-481a-9009-74812a6c4006",
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_data_reg_v_a = hssm_reg_v_a_angle.sample(\n",
    "    sampler=\"nuts_numpyro\", chains=2, cores=1, draws=1000, tune=1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98284eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(infer_data_reg_v_a, var_names = ['~a', '~v']) # , var_names=[\"~rt,response_a\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd66b7c-9040-4294-aacf-1ea800d0d909",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(hssm_reg_v_a_angle.traces, \n",
    "              var_names = ['~v', '~a'],\n",
    "              lines = [(key_, {}, param_dict_reg_v_a[key_]) for key_ in param_dict_reg_v_a])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4fcfad",
   "metadata": {},
   "source": [
    "We successfully recover our regression betas for `a`! Moreover, no warning signs concerning our chains."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d0dc49-4aa5-454c-b519-2033e2494266",
   "metadata": {},
   "source": [
    "### Case 4: Categorical covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c863b96-9782-4faa-baef-4ea8beddb23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up trial by trial parameters\n",
    "x = np.random.choice(4, size=1000).astype(int)\n",
    "x_offset = np.array([0, 1, -0.5, 0.75])\n",
    "y\n",
    "\n",
    "y = np.random.uniform(-1, 1, size=1000)\n",
    "v_y = 0.3\n",
    "v_reg_v = 0 + (v_y * y) + x_offset[x]\n",
    "\n",
    "# rest\n",
    "a_reg_v = 1.5\n",
    "z_reg_v = 0.5\n",
    "t_reg_v = 0.1\n",
    "\n",
    "# base dataset\n",
    "dataset_reg_v_cat = hssm.simulate_data(model = 'ddm',\n",
    "                                   theta = dict(v = v_reg_v,\n",
    "                                                a = a_reg_v,\n",
    "                                                z = z_reg_v,\n",
    "                                                t = t_reg_v),\n",
    "                                   size = 1)\n",
    "\n",
    "# Adding covariates into the datsaframe\n",
    "dataset_reg_v_cat['x'] = x\n",
    "dataset_reg_v_cat['y'] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d2f59a-a792-4398-9eba-5dbbaeb14cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_reg_v_cat = hssm.HSSM(\n",
    "    data=dataset_reg_v_cat,\n",
    "    model=\"angle\",\n",
    "    include=[\n",
    "        {\n",
    "            \"name\": \"v\",\n",
    "            \"formula\": \"v ~ 0 + C(x) + y\",\n",
    "            \"link\": \"identity\",\n",
    "        }\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dbcf6fd-c97a-4d37-b2e9-08774a607321",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_reg_v_cat.graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8fe60ab-4a6e-4e26-aeff-00cc57ea9a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_data_reg_v_cat = model_reg_v_cat.sample(\n",
    "        sampler=\"nuts_numpyro\", \n",
    "        chains=2, cores=1, \n",
    "        draws=1000, tune=500\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced758fc-06b4-4ec3-ba36-6dc046e3c4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_forest(infer_data_reg_v_cat, var_names = [\"~v\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c97e45",
   "metadata": {},
   "source": [
    "## Hierarchical Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0d08cd",
   "metadata": {},
   "source": [
    "Let's try to fit a hierarchical model now. We will simulate a dataset with $15$ participants, with $200$ observations / trials for each participant. \n",
    "\n",
    "We define a group mean `mean_v` and a group standard deviation `sd_v` for the intercept parameter of the regression on `v`, which we sample from a corresponding normal distribution for each participant."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bfd0871",
   "metadata": {},
   "source": [
    "### Simulate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85756d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make some hierarchical data\n",
    "\n",
    "n_participants = 15  # number of participants\n",
    "n_trials = 200  # number of trials per participant\n",
    "\n",
    "sd_v = 0.5  # sd for v-intercept\n",
    "mean_v = 0.5  # mean for v-intercept\n",
    "\n",
    "data_list = []\n",
    "for i in range(n_participants):\n",
    "    # Make parameters for participant i\n",
    "    v_intercept_hier = np.random.normal(mean_v, sd_v, size=1)\n",
    "    x = np.random.uniform(-1, 1, size=n_trials)\n",
    "    v_x_hier = 0.8\n",
    "    y = np.random.uniform(-1, 1, size=n_trials)\n",
    "    v_y_hier = 0.3\n",
    "    v_hier = v_intercept_hier + (v_x_hier * x) + (v_y_hier * y)\n",
    "\n",
    "    a_hier = 1.5\n",
    "    t_hier = 0.5\n",
    "    z_hier = 0.5\n",
    "\n",
    "    # true_values = np.column_stack(\n",
    "    #     [v, np.repeat([[1.5, 0.5, 0.5, 0.0]], axis=0, repeats=n_trials)]\n",
    "    # )\n",
    "\n",
    "    data_tmp = hssm.simulate_data(model = \"ddm\", \n",
    "                                  theta = dict(v = v_hier,\n",
    "                                                     a = a_hier,\n",
    "                                                     z = z_hier,\n",
    "                                                     t = t_hier),\n",
    "                                  size = 1)\n",
    "    data_tmp['participant_id'] = i\n",
    "    data_tmp['x'] = x\n",
    "    data_tmp['y'] = y\n",
    "\n",
    "    data_list.append(data_tmp)\n",
    "    \n",
    "# Make single dataframe out of participant-wise datasets\n",
    "dataset_reg_v_hier = pd.concat(data_list)\n",
    "dataset_reg_v_hier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f293f0b8",
   "metadata": {},
   "source": [
    "We can now define our `HSSM` model. \n",
    "\n",
    "We specify the regression as `v ~ 1 + (1|participant_id) + x + y`. \n",
    "\n",
    "`(1|participant_id)` tells the model to create a *participant-wise* offset for the intercept parameter. The rest of the regression $\\beta$'s is fit globally. \n",
    "\n",
    "As an **R** user you may recognize this syntax from the [lmer](https://www.rdocumentation.org/packages/lme4/versions/1.1-33/topics/lmer) package. \n",
    "\n",
    "Our [Bambi](https://bambinos.github.io/bambi/) backend is essentially a Bayesian version of [lmer](https://www.rdocumentation.org/packages/lme4/versions/1.1-33/topics/lmer), quite like the [BRMS](https://cran.r-project.org/web/packages/brms/index.html) package in **R**, which operates on top of [STAN](https://mc-stan.org/). \n",
    "\n",
    "As a previous [HDDM](https://hddm.readthedocs.io/en/latest/) user, you may recognize that now proper mixed-effect models are viable! \n",
    "\n",
    "You should be able to handle between and within participant effects naturally now!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfba6da-7327-49a4-8e52-9a468fcb28d3",
   "metadata": {},
   "source": [
    "### Basic Hierarchical Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9537184",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_reg_v_angle_hier = hssm.HSSM(\n",
    "    data=dataset_reg_v_hier,\n",
    "    model=\"angle\",\n",
    "    noncentered=True,\n",
    "    include=[\n",
    "        {\n",
    "            \"name\": \"v\",\n",
    "            \"prior\": {\n",
    "                \"Intercept\": {\n",
    "                    \"name\": \"Normal\",\n",
    "                    \"mu\": 0.,\n",
    "                    \"sigma\": 0.5,\n",
    "                    \"initval\": 0.0,\n",
    "                },\n",
    "                \"x\": {\"name\": \"Normal\", \"mu\": 0.0, \"sigma\": 0.5, \"initval\": 0.0},\n",
    "                \"y\": {\"name\": \"Normal\", \"mu\": 0.0, \"sigma\": 0.5, \"initval\": 0.0},\n",
    "            },\n",
    "            \"formula\": \"v ~ 1 + (1|participant_id) + x + y\",\n",
    "            \"link\": \"identity\",\n",
    "        }\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d82a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_reg_v_angle_hier.graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54711986",
   "metadata": {},
   "outputs": [],
   "source": [
    "jax.config.update(\"jax_enable_x64\", False)\n",
    "model_reg_v_angle_hier.sample(\n",
    "    sampler=\"nuts_numpyro\", chains=2, cores=1, draws=1000, tune=1000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704fc2af",
   "metadata": {},
   "source": [
    "Let's look at the posteriors!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c12c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_forest(model_reg_v_angle_hier.traces, var_names = ['~v', '~a'], combined=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3cd05f",
   "metadata": {},
   "source": [
    "## Model Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac41b720",
   "metadata": {},
   "source": [
    "Fitting single models is all well and good. We are however, often interested in comparing how well a few different models account for the same data. \n",
    "\n",
    "Through [ArviZ](https://python.arviz.org/en/stable/index.html), we have out of the box access to modern Bayesian Model Comparison. We will keep it simple here, just to illustrate the basic idea. \n",
    "\n",
    "### Scenario\n",
    "\n",
    "The following scenario is explored. \n",
    "\n",
    "First we generate data from a `ddm` model with fixed parameters, specifically we set the `a` parameter to $1.5$. \n",
    "\n",
    "We then define two `HSSM` models:\n",
    "\n",
    "1. A model which allows fitting all but the `a` parameter, which is fixed to $1.0$ (wrong)\n",
    "2. A model which allows fitting all but the `a` parameter, which is fixed to $1.5$ (correct)\n",
    "\n",
    "We then use the [ArviZ](https://python.arviz.org/en/stable/index.html)'s `compare()` function, to perform model comparison via `elpd_loo`. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47c76a2",
   "metadata": {},
   "source": [
    "### Data Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73468f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "param_dict_mod_comp = dict(v = 0.5, \n",
    "                           a = 1.5,\n",
    "                           z = 0.5,\n",
    "                           t = 0.2)\n",
    "\n",
    "# Simulation\n",
    "dataset_model_comp = hssm.simulate_data(model = \"ddm\",\n",
    "                                        theta = param_dict_mod_comp,\n",
    "                                        size = 500)\n",
    "\n",
    "print(dataset_model_comp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb87955",
   "metadata": {},
   "source": [
    "### Defining the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ced4489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'wrong' model\n",
    "model_model_comp_1 = hssm.HSSM(\n",
    "    data=dataset_model_comp,\n",
    "    model=\"angle\",\n",
    "    a=1.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7cfda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'correct' model\n",
    "model_model_comp_2 = hssm.HSSM(\n",
    "    data=dataset_model_comp,\n",
    "    model=\"angle\",\n",
    "    a=1.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e44176af-7dc9-4871-88b1-58b5f7c9f091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'wrong' model ddm\n",
    "model_model_comp_3 = hssm.HSSM(\n",
    "    data=dataset_model_comp,\n",
    "    model=\"ddm\",\n",
    "    a=1.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba5ab83",
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_data_model_comp_1 = model_model_comp_1.sample(\n",
    "    sampler=\"nuts_numpyro\",\n",
    "    cores=1,\n",
    "    chains=2,\n",
    "    draws=1000,\n",
    "    tune=1000,\n",
    "    idata_kwargs=dict(\n",
    "        log_likelihood=True\n",
    "    ),  # model comparison metrics usually need this!\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ff738a",
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_data_model_comp_2 = model_model_comp_2.sample(\n",
    "    sampler=\"nuts_numpyro\",\n",
    "    cores=1,\n",
    "    chains=2,\n",
    "    draws=1000,\n",
    "    tune=1000,\n",
    "    idata_kwargs=dict(\n",
    "        log_likelihood=True\n",
    "    ),  # model comparison metrics usually need this!\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0a9f3d-4d5f-4943-b16c-5656098d2b79",
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_data_model_comp_3 = model_model_comp_3.sample(\n",
    "    sampler=\"nuts_numpyro\",\n",
    "    cores=1,\n",
    "    chains=2,\n",
    "    draws=1000,\n",
    "    tune=1000,\n",
    "    idata_kwargs=dict(\n",
    "        log_likelihood=True\n",
    "    ),  # model comparison metrics usually need this!\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b681dafc",
   "metadata": {},
   "source": [
    "### Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80464b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_data = az.compare(\n",
    "    {\n",
    "        \"a_fixed_1(wrong)\": model_model_comp_1.traces,\n",
    "        \"a_fixed_1.5(correct)\": model_model_comp_2.traces,\n",
    "        \"a_fixed_1_ddm(wrong)\": model_model_comp_3.traces,\n",
    "    }\n",
    ")\n",
    "\n",
    "compare_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ccc727",
   "metadata": {},
   "source": [
    "Notice how the posterior weight on the `correct` model is close to (or equal to ) $1$ here. \n",
    "In other words model comparison points us to the correct model with \n",
    "a very high degree of certainty here!\n",
    "\n",
    "\n",
    "We can also use the `.plot_compare()` function to illustrate the model comparison visually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3175f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_compare(compare_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d148365-c44a-4641-a4c6-dcac22f99ed2",
   "metadata": {},
   "source": [
    "Using the forest plot we can take a look at what goes wrong for the \"wrong\" model. \n",
    "\n",
    "To make up for the mistplaced setting of the `a` parameter, the posterior seems to compensate by\n",
    "mis-estimating the other parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae3635e8-1d71-4cd6-9d90-6b70ba6ee875",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_forest([model_model_comp_1.traces, \n",
    "                model_model_comp_2.traces, \n",
    "                model_model_comp_3.traces], model_names = [\"a_fixed_1(wrong)\", \n",
    "                                                           \"a_fixed_1.5(correct)\",\n",
    "                                                           \"a_fixed_1(wrong)_ddm\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5387ba",
   "metadata": {},
   "source": [
    "## Closer look!\n",
    "\n",
    "<center> <img src=\"images/pytensor_jax.png\" height=\"400\" width=\"400\"> </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce2b39b",
   "metadata": {},
   "source": [
    "We have seen a few examples of HSSM models at this point. Add a model via a string, maybe toy a bit with with the priors and set regression functions for a given parameter. Turn it hierarchical...  Here we begin to peak a bit under the hood. \n",
    "\n",
    "After all, we want to encourage you to contribute models to the package yourself. \n",
    "\n",
    "Let's remind ourself of the `model_config` dictionaries that define model properties for us. Again let's start with the DDM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb0ef7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "hssm.config.default_model_config[\"ddm\"].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea05819",
   "metadata": {},
   "source": [
    "The dictionary has a few high level keys. \n",
    "\n",
    "1. `response`\n",
    "\n",
    "2. `list_params`\n",
    "\n",
    "3. `description`\n",
    "\n",
    "4. `likelihoods`\n",
    "\n",
    "\n",
    "Let us take a look at the available `likelihoods`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a158ea-4a86-47f8-a23a-836239af8f63",
   "metadata": {},
   "outputs": [],
   "source": [
    "hssm.config.default_model_config[\"ddm\"][\"likelihoods\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3a1ac4-d6f0-4d66-825a-59639425d4c7",
   "metadata": {},
   "source": [
    "For the DDM we have available all three types of likelihoods that HSSM deals with:\n",
    "\n",
    "1. `analytical`\n",
    "2. `approx_differentiable`\n",
    "3. `blackbox`\n",
    "\n",
    "Let's expand the dictionary contents more:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a964760",
   "metadata": {},
   "outputs": [],
   "source": [
    "hssm.config.default_model_config[\"ddm\"][\"likelihoods\"][\"analytical\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ca6d97",
   "metadata": {},
   "source": [
    "We see three properties (key) in this dictionary, of which two are essential:\n",
    "\n",
    "- The `loglik` field, which points to the likelihood function\n",
    "- The `backend` field, which can be either `None` (defaulting to pytensor for `analytical` likelihoods), `jax` or `pytensor`\n",
    "- The `bounds` field, which specifies bounds on a subset of the model parameters\n",
    "- The `default_priors` field, which specifies parameter wise priors\n",
    "\n",
    "If you provide `bounds` for a parameter, but no `default_priors`, a *Uniform* prior that respects the specified bounds will be applied. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8d6764",
   "metadata": {},
   "source": [
    "Next, let's look at the `approx_differentiable` part. \n",
    "The likelihood in this part is based on a [LAN]() which was available in [HDDM]() through the [LAN extension](). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5338450",
   "metadata": {},
   "outputs": [],
   "source": [
    "hssm.config.default_model_config[\"ddm\"][\"likelihoods\"][\"approx_differentiable\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3f1d69",
   "metadata": {},
   "source": [
    "We see that the `loglik` field is now a string that points to a `.onnx` file. \n",
    "[Onnx](https://onnx.ai/) is a meta framework for Neural Network specification, that allows translation between deep learning Frameworks. This is the preferred format for the neural networks we store in our model reservoir on [HuggingFace](https://huggingface.co/).\n",
    "\n",
    "Moreover notice that we now have a `backend` field. We allow for two primary backends in the `approx_differentiable` field. \n",
    "\n",
    "1. `pytensor`\n",
    "2. `jax` \n",
    "\n",
    "The `jax` backend assumes that your likelihood is described as a jax function, the `pytensor` backend assumes that your likelihood is described as a `pytensor` function. Ok not that surprising...\n",
    "\n",
    "We won't dwell on this here, however the key idea is to provide users with a large degree of flexibility in describing their likelihood functions and moreover to allow targeted optimization towards MCMC sampler types that [PyMC]() allows us to access.\n",
    "\n",
    "You can find a [dedicated tutorial](https://lnccbrown.github.io/HSSM/tutorial_likelihoods/#3-kinds-of-likelihoods) in the documentation, which describes the different likelihoods in much more detail. \n",
    "\n",
    "Instead, let's take a quick look at how these newfound insights can be used for custom model definition. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e97152",
   "metadata": {},
   "outputs": [],
   "source": [
    "hssm_alternative_model = hssm.HSSM(\n",
    "    data=dataset,\n",
    "    model=\"ddm\",\n",
    "    loglik_kind=\"approx_differentiable\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a501191d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hssm_alternative_model.loglik_kind"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070e07d2",
   "metadata": {},
   "source": [
    "In this case we actually built the model class with an `approx_differentiable` LAN likelihood, instead of the default `analytical` likelihood we used in the beginning of the tutorial. The assumed generative model remains the `ddm` however!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af6a107",
   "metadata": {},
   "outputs": [],
   "source": [
    "hssm_alternative_model.sample(\n",
    "    sampler=\"nuts_numpyro\",\n",
    "    cores=1,\n",
    "    chains=2,\n",
    "    draws=1000,\n",
    "    tune=1000,\n",
    "    idata_kwargs=dict(\n",
    "        log_likelihood=False\n",
    "    ),  # model comparison metrics usually need this!\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100d4694",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_forest(hssm_alternative_model.traces)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac07dbcf",
   "metadata": {},
   "source": [
    "We can take this further and specify a completely custom likelihood. See the [dedicated tutorial](https://lnccbrown.github.io/HSSM/tutorial_likelihoods/#using-custom-likelihoods) for more examples!\n",
    "\n",
    "We will see one specific example below to illustrate another type of likelihood function we have available for model building in HSSM, the *Blackbox* likelihood. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16e6ba5",
   "metadata": {},
   "source": [
    "## 'Blackbox' Likelihoods\n",
    "\n",
    "<center> <img src=\"images/blackbox.png\" height=\"400\" width=\"400\"> </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127b3fbb",
   "metadata": {},
   "source": [
    "### What is a **Blackbox Likelihood Function**?\n",
    "\n",
    "A *Blackbox Likelihood Function* is essentially any Python `callable` (function) that provides trial by trial likelihoods for your model of interest. What kind of computations are performed in this Python function is completely arbitrary. \n",
    "\n",
    "E.g. you could built a function that performs forward simulation from you model, constructs are kernel-density estimate for the resulting likelihood functions and evaluates your datapoints on this ad-hoc generated approximate likelihood.\n",
    "\n",
    "What I just described is a once state-of-the-art method of performing simulation based inference on Sequential Sampling models, a precursor to LANs if you will."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db21467",
   "metadata": {},
   "source": [
    "We will do something simpler to keep it short and sweet, but really... the possibilities are endless!\n",
    "\n",
    "<br> </br>\n",
    "<center><img src=\"https://media.giphy.com/media/juq2OXONntuHfLc4Tn/giphy.gif\" style=\"margin:auto\" height=\"300\" width=\"300\"/></center>\n",
    "<br> </br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7715a162",
   "metadata": {},
   "source": [
    "### Simulating simple dataset from the DDM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efe8587",
   "metadata": {},
   "source": [
    "As always, let's begin by generating some simple dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7723911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "param_dict_blackbox = dict(v = 0.5,\n",
    "                           a = 1.5,\n",
    "                           z = 0.5,\n",
    "                           t = 0.5)\n",
    "\n",
    "# Simulate\n",
    "dataset_blackbox = hssm.simulate_data(model=\"ddm\",\n",
    "                                      theta=param_dict_blackbox,\n",
    "                                      size = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca08b20d",
   "metadata": {},
   "source": [
    "### Define the likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3224af31",
   "metadata": {},
   "source": [
    "Now the fun part... we simply define a Python function `my_blackbox_loglik` which takes in our `data` as well as a bunch of model parameters (in our case the familiar `v`,`a`, `z`, `t` from the DDM).\n",
    "\n",
    "The function then does some arbitrary computation inside (in our case e.g. we pass the data and parameters to the DDM log-likelihood from our predecessor package HDDM).\n",
    "\n",
    "The important part is that inside `my_blackbox_loglik` anything can happen. We happen to call a little custom function that defines the likelihood of a DDM.\n",
    "\n",
    "**Fun fact:**\n",
    "It is de-facto the likelihood which is called by [HDDM](https://hddm.readthedocs.io/en/latest/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954c86d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_blackbox_loglik(data, v, a, z, t, err=1e-8):\n",
    "    data = data[:, 0] * data[:, 1]\n",
    "    # Our function expects inputs as float64, but they are not guaranteed to\n",
    "    # come in as such --> we type convert\n",
    "    return hddm_wfpt.wfpt.pdf_array(\n",
    "        np.float64(data),\n",
    "        np.float64(v),\n",
    "        0,\n",
    "        np.float64(2 * a),\n",
    "        np.float64(z),\n",
    "        0,\n",
    "        np.float64(t),\n",
    "        0,\n",
    "        err,\n",
    "        1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce344b29",
   "metadata": {},
   "source": [
    "### Define HSSM class with our Blackbox Likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c30245",
   "metadata": {},
   "source": [
    "We can now define our HSSM model class as usual, however passing our `my_blackbox_loglik()` function to the `loglik` argument, and passing as `loglik_kind = blackbox`. \n",
    "\n",
    "The rest of the model config is as usual. Here we can reuse our `ddm` model config, and simply specify bounds on the parameters (e.g. your Blackbox Likelihood might be trustworthy only on a restricted parameters space). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cde9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "blackbox_model = hssm.HSSM(\n",
    "    data=dataset_blackbox,\n",
    "    model=\"ddm\",\n",
    "    loglik=my_blackbox_loglik,\n",
    "    loglik_kind=\"blackbox\",\n",
    "    model_config={\n",
    "        \"bounds\": {\n",
    "            \"v\": (-10.0, 10.0),\n",
    "            \"a\": (0.5, 5.0),\n",
    "            \"z\": (0.0, 1.0),\n",
    "        }\n",
    "    },\n",
    "    t=bmb.Prior(\"Uniform\", lower=0.0, upper=2.0, initval=0.1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1490c518",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = blackbox_model.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a4e5a0f",
   "metadata": {},
   "source": [
    "**NOTE**:\n",
    "\n",
    "Since *Blackbox likelihood functions* are assumed to not be differentiable, our default sampler for such likelihood functions is a `Slice` sampler. HSSM allows you to choose any other suitable sampler from the PyMC package instead. A bunch of options are available for gradient-free samplers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574d596f",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1698db",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.summary(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11709aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(sample, lines = [(key_, {}, param_dict_blackbox[key_]) for key_ in param_dict_blackbox])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ef375f",
   "metadata": {},
   "source": [
    "## HSSM Random Variables in PyMC\n",
    "\n",
    "We covered a lot of ground in this tutorial so far. You are now a sophisticated HSSM user. \n",
    "\n",
    "It is therefore time to reveal a secret. We can actuallly peel back one more layer...\n",
    "<br> </br>\n",
    "<center><img src=\"https://media.giphy.com/media/3o6EhKIVvdhTkvjT8s/giphy.gif\" style=\"margin:auto\" height=\"300\" width=\"300\"/></center>\n",
    "<br> </br>\n",
    "\n",
    "Instead of letting HSSM help you build the entire model, we can instead use HSSM to construct valid [PyMC](https://www.pymc.io/welcome.html) distributions and then proceed to build a custom PyMC model by ourselves...\n",
    "<br> </br>\n",
    "<center><img src=\"https://media.giphy.com/media/3pDxFfu5yZblPUVnWY/giphy.gif\" style=\"margin:auto\" height=\"300\" width=\"300\"/></center>\n",
    "<br> </br>\n",
    "\n",
    "We will illustrate the simplest example below. It sets a pattern that can be exploited for much more complicated modeling exercises, which importantly go far beyond what our basic HSSM class may facilitate for you! \n",
    "\n",
    "See the [dedicated tutorial](https://lnccbrown.github.io/HSSM/notebooks/pymc/) in the [documentation](https://lnccbrown.github.io/HSSM/) if you are interested.\n",
    "\n",
    "Let's start by importing a few convenience functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "674030cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DDM models (the Wiener First-Passage Time distribution)\n",
    "from hssm.likelihoods import logp_ddm_sdv, DDM\n",
    "from hssm.distribution_utils import make_distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b5ea9ce",
   "metadata": {},
   "source": [
    "### Simulate some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2652fa13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate\n",
    "param_dict_pymc = dict(v = 0.5,\n",
    "                       a = 1.5,\n",
    "                       z = 0.5,\n",
    "                       t = 0.5,\n",
    "                       theta = 0.0)\n",
    "\n",
    "dataset_pymc = hssm.simulate_data(model=\"ddm\",\n",
    "                                  theta=param_dict_pymc,\n",
    "                                  size=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad48a160",
   "metadata": {},
   "source": [
    "### Build a custom PyMC Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ff5d3d",
   "metadata": {},
   "source": [
    "We can now use our custom random variable `DDM` directly in a PyMC model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d6cd78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc as pm\n",
    "\n",
    "with pm.Model() as ddm_pymc:\n",
    "    v = pm.Uniform(\"v\", lower=-10.0, upper=10.0)\n",
    "    a = pm.HalfNormal(\"a\", sigma=2.0)\n",
    "    z = pm.Uniform(\"z\", lower=0.01, upper=0.99)\n",
    "    t = pm.Uniform(\"t\", lower=0.0, upper=0.6, initval=0.1)\n",
    "\n",
    "    ddm = DDM(\"DDM\", v=v, a=a, z=z, t=t, observed=dataset_pymc[['rt', 'response']].values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95d26e23",
   "metadata": {},
   "source": [
    "Let's check the model graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30da0d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pm.model_to_graphviz(model=ddm_pymc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c892c2",
   "metadata": {},
   "source": [
    "Looks remarkably close to our HSSM version!\n",
    "\n",
    "We can use PyMC directly to sample and finally return to ArviZ for some plotting!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14d8607",
   "metadata": {},
   "outputs": [],
   "source": [
    "with ddm_pymc:\n",
    "    ddm_pymc_trace = pm.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bf9533",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(ddm_pymc_trace, lines = [(key_, {}, param_dict_pymc[key_]) for key_ in param_dict_pymc])\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0444c0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_forest(ddm_pymc_trace)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c480ca1-01f6-4cf3-91bf-834b691bc9e2",
   "metadata": {},
   "source": [
    "### Alternative Models with PyMC\n",
    "\n",
    "With very little extra work, we can in fact load any of the models accessible via HSSM. Here is an example, where we load the `angle` model instead. \n",
    "\n",
    "We first construction the likelihood function, using `make_likelihood_callable()`. \n",
    "\n",
    "Then we produce a valid `pymc.distribution` using the \n",
    "`make_distribution()` utility function.\n",
    "\n",
    "Just like the `DDM` class above, we can then use this distribution inside a **PyMC** model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12de0505-27b0-4df2-9a88-384a39d5eb19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hssm.distribution_utils import make_likelihood_callable, make_distribution\n",
    "\n",
    "angle_loglik = make_likelihood_callable(loglik='angle.onnx', \n",
    "                                        loglik_kind='approx_differentiable', \n",
    "                                        backend='jax', \n",
    "                                        params_is_reg=[0, 0, 0, 0, 0])\n",
    "\n",
    "ANGLE = make_distribution('angle', loglik = angle_loglik, list_params = hssm.defaults.default_model_config['angle']['list_params'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3692b8-835a-4e0f-bcee-63e05be6d632",
   "metadata": {},
   "source": [
    "Note that we need to supply the `params_is_reg` argument (\"reg\" for \"regression\"). \n",
    "This is a boolean vector, which specifies for each input to the likelihood function, whether or not it is defined to be \"trial-wise\", as is expected if the parameter\n",
    "is the output e.g. of a regression function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2286dda9-14df-417c-b447-5bcb9630836b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymc as pm\n",
    "\n",
    "# Angle pymc\n",
    "with pm.Model() as angle_pymc:\n",
    "    # Define parameters\n",
    "    v = pm.Uniform(\"v\", lower=-10.0, upper=10.0)\n",
    "    a = pm.Uniform(\"a\", lower=0.5, upper=2.5)\n",
    "    z = pm.Uniform(\"z\", lower=0.01, upper=0.99)\n",
    "    t = pm.Uniform(\"t\", lower=0.0, upper=0.6, initval=0.1)\n",
    "    theta = pm.Uniform(\"theta\", lower=-0.1, upper=1.0, initval= 0.2)\n",
    "\n",
    "    # Our RV\n",
    "    angle = ANGLE(\"DDM\", v=v, a=a, z=z, t=t, theta=theta, observed=dataset_pymc[['rt', 'response']].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e1765d-5c6f-4481-a88b-06933616100c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with angle_pymc:\n",
    "    idata_object = pm.sample(nuts_sampler=\"numpyro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dea880b-7d44-4e6b-b628-d71e7c67ad10",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(idata_object, \n",
    "              lines = [(key_, {}, param_dict_pymc[key_]) for key_ in param_dict_pymc])\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03ce970d-6328-4d64-a850-d3feb8e9fe0d",
   "metadata": {},
   "source": [
    "### Regression via PyMC\n",
    "\n",
    "Finally to illustrate the usage of PyMC a little more elaborately, let us build a PyMC model with regression components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1d91a0-bed0-4198-864b-e8aeee80d3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "def make_params_is_reg_vec(reg_parameters: Optional[list] = None, \n",
    "                           parameter_names: Optional[list] = None):\n",
    "    if (not isinstance(reg_parameters, list)) or (not isinstance(parameter_names, list)):\n",
    "        raise ValueError('Both reg_parameters and parameter_names should be lists')\n",
    "\n",
    "    bool_list = [0]*len(parameter_names)\n",
    "    for param in reg_parameters:\n",
    "        bool_list[parameter_names.index(param)] = 1\n",
    "    return bool_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef35e156-1e01-4c18-91b5-39ecaac73c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up trial by trial parameters\n",
    "v_intercept_pymc_reg = 0.3\n",
    "x_pymc_reg = np.random.uniform(-1, 1, size=1000)\n",
    "v_x_pymc_reg = 0.8\n",
    "y_pymc_reg = np.random.uniform(-1, 1, size=1000)\n",
    "v_y_pymc_reg = 0.3\n",
    "v_pymc_reg = v_intercept + (v_x * x) + (v_y * y)\n",
    "\n",
    "param_dict_pymc_reg = dict(v_Intercept = v_intercept_pymc_reg,\n",
    "                           v_x = v_x_pymc_reg,\n",
    "                           v_y = v_y_pymc_reg,\n",
    "                           v = v_pymc_reg,\n",
    "                           a = 1.5,\n",
    "                           z = 0.5,\n",
    "                           t = 0.1,\n",
    "                           theta = 0.0)\n",
    "                           \n",
    "# base dataset\n",
    "pymc_reg_data = hssm.simulate_data(model = 'ddm',\n",
    "                                   theta = param_dict_pymc_reg,\n",
    "                                   size = 1)\n",
    "\n",
    "# Adding covariates into the datsaframe\n",
    "pymc_reg_data['x'] = x\n",
    "pymc_reg_data['y'] = y\n",
    "\n",
    "# Make the boolean vector for params_is_reg argument\n",
    "bool_param_reg = make_params_is_reg_vec(reg_parameters = ['v'], \n",
    "                                        parameter_names = hssm.defaults.default_model_config['angle']['list_params'])\n",
    "\n",
    "angle_loglik = make_likelihood_callable(loglik='angle.onnx',\n",
    "                                        loglik_kind='approx_differentiable', \n",
    "                                        backend='jax', \n",
    "                                        params_is_reg=bool_param_reg)\n",
    "\n",
    "ANGLE = make_distribution('angle', \n",
    "                          loglik = angle_loglik, \n",
    "                          list_params = hssm.defaults.default_model_config['angle']['list_params'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11bf8a1-29a4-46d1-a642-17ebce3eb8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytensor.tensor as pt\n",
    "with pm.Model(coords = {'idx': pymc_reg_data.index,\n",
    "                        'resp': ['rt', 'response'],\n",
    "                        'features': ['x', 'y']}) as pymc_model_reg:\n",
    "\n",
    "    # Features\n",
    "    x_ = pm.Data('x', pymc_reg_data['x'].values, dims='idx')\n",
    "    y_ = pm.Data('y', pymc_reg_data['y'].values, dims='idx')\n",
    "    # Target\n",
    "    obs = pm.Data('obs', pymc_reg_data[['rt', 'response']].values, dims=('idx', 'resp'))\n",
    "    \n",
    "    # Priors\n",
    "    a = pm.Uniform(\"a\", lower=0.5, upper=2.5)\n",
    "    z = pm.Uniform(\"z\", lower=0.01, upper=0.99)\n",
    "    t = pm.Uniform(\"t\", lower=0.0, upper=0.6, initval=0.1)\n",
    "    theta = pm.Uniform(\"theta\", lower=-0.1, upper=1.0, initval= 0.2)\n",
    "    v_Intercept = pm.Uniform(\"v_Intercept\", lower=-3, upper=3)\n",
    "    v_betas = pm.Normal(\"v_beta\", mu = [0, 0], sigma= 0.5, dims=('features'))\n",
    "    \n",
    "    # Regression equation\n",
    "    v = pm.Deterministic('v', v_Intercept + pt.stack([x_, y_], axis=1) @ v_betas, dims='idx')\n",
    "    \n",
    "    # Our RV\n",
    "    angle = ANGLE(\"angle\", v=v.squeeze(), a=a, z=z, t=t, theta=theta, observed=obs, dims=('idx', 'resp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880c7b36-5143-4037-b94e-fe3205c55182",
   "metadata": {},
   "outputs": [],
   "source": [
    "with pymc_model_reg:\n",
    "    idata_pymc_reg = pm.sample(nuts_sampler=\"numpyro\", idata_kwargs={'log_likelihood': True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5254e5-de86-482e-af24-740f813ca52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_forest(idata_pymc_reg, var_names=['~v'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1f1266",
   "metadata": {},
   "source": [
    "All layers peeled back, the only limit in your modeling endeavors becomes the limit of the PyMC universe!\n",
    "\n",
    "<br> </br>\n",
    "\n",
    "<center><img src=\"https://media.giphy.com/media/4ydWTcMBjimLbT1CHi/giphy.gif\" style=\"margin:auto\" height=\"300\" width=\"300\"/></center>\n",
    "\n",
    "\n",
    "<center> Enjoy the exploration! </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2905aa9e",
   "metadata": {},
   "source": [
    "# End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hssm_pymc516",
   "language": "python",
   "name": "hssm_pymc516"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
