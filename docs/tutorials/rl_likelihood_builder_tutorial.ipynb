{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e6b07c2",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c314434",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from jax.lax import scan\n",
    "\n",
    "import hssm\n",
    "from hssm.rl.likelihoods.builder import (\n",
    "    annotate_function,\n",
    "    make_rl_logp_func,\n",
    "    compute_v_trial_wise,\n",
    "    compute_v_subject_wise,\n",
    "    angle_logp_jax_func,\n",
    "    _get_column_indices,\n",
    "    _get_column_indices_with_computed,\n",
    "    _collect_cols_arrays,\n",
    ")\n",
    "\n",
    "hssm.set_floatX(\"float32\")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6219fa",
   "metadata": {},
   "source": [
    "# Building Complete Likelihoods with `make_rl_logp_func`\n",
    "1. Identifies which parameters come from data vs. model parameters\n",
    "2. Computes derived parameters (like drift rates from RL)\n",
    "3. Assembles everything into a complete log-likelihood function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c4e4d2",
   "metadata": {},
   "source": [
    "### 1. Setting up the components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6490017f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1: Annotate the learning rule function\n",
    "compute_v_annotated = annotate_function(\n",
    "    inputs=[\"rl.alpha\", \"scaler\", \"response\", \"feedback\"],\n",
    "    outputs=[\"v\"]\n",
    ")(compute_v_subject_wise)\n",
    "\n",
    "vars(compute_v_annotated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9404258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2: Annotate the SSM likelihood function\n",
    "# This function needs 'v' as input, but 'v' is computed by our learning rule\n",
    "ssm_logp_annotated = annotate_function(\n",
    "    inputs=[\"v\", \"a\", \"z\", \"t\", \"theta\", \"rt\", \"response\"],\n",
    "    computed={\"v\": compute_v_annotated}  # Specify the dependency\n",
    ")(angle_logp_jax_func)\n",
    "\n",
    "vars(ssm_logp_annotated)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd55bce",
   "metadata": {},
   "source": [
    "### 2. Creating the complete log-likelihood function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb70bb5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulation parameters\n",
    "n_participants = 5\n",
    "n_trials_per_subject = 40\n",
    "total_trials = n_participants * n_trials_per_subject\n",
    "\n",
    "# Create complete dataset\n",
    "data_matrix = np.column_stack([\n",
    "    np.random.uniform(0.3, 1.5, total_trials),  # rt\n",
    "    np.random.choice([-1, 1], total_trials)     # response\n",
    "])\n",
    "\n",
    "# Define parameter structure\n",
    "data_cols = [\"rt\", \"response\"]\n",
    "list_params = [\"rl.alpha\", \"scaler\", \"a\", \"z\", \"t\", \"theta\"]\n",
    "extra_fields = [\"feedback\"]\n",
    "\n",
    "# Build the log-likelihood function!\n",
    "logp_func = make_rl_logp_func(\n",
    "    ssm_logp_func=ssm_logp_annotated,\n",
    "    n_participants=n_participants,\n",
    "    n_trials=n_trials_per_subject,\n",
    "    data_cols=data_cols,\n",
    "    list_params=list_params,\n",
    "    extra_fields=extra_fields\n",
    ")\n",
    "\n",
    "print(\"Complete log-likelihood function created!\")\n",
    "print(f\"\\nThis function will:\")\n",
    "print(f\"  1. Extract parameters from data and args\")\n",
    "print(f\"  2. Compute drift rates using the RL model\")\n",
    "print(f\"  3. Evaluate the SSM likelihood\")\n",
    "print(f\"  4. Return log-likelihood for all {total_trials} trials\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f96c2d9",
   "metadata": {},
   "source": [
    "### 3. Using the log-likelihood function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d780083f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create parameter arrays\n",
    "rl_alpha = np.ones(total_trials) * 0.6\n",
    "scaler = np.ones(total_trials) * 3.2\n",
    "a = np.ones(total_trials) * 1.2\n",
    "z = np.ones(total_trials) * 0.5\n",
    "t = np.ones(total_trials) * 0.1\n",
    "theta = np.ones(total_trials) * 0.3\n",
    "feedback = np.random.choice([0, 1], total_trials)\n",
    "\n",
    "# Evaluate log-likelihood\n",
    "logp_values = logp_func(data_matrix, rl_alpha, scaler, a, z, t, theta, feedback)\n",
    "\n",
    "print(f\"Log-likelihood evaluation:\")\n",
    "print(f\"  Output shape: {logp_values.shape}\")\n",
    "print(f\"  Total log-likelihood: {logp_values.sum():.2f}\")\n",
    "print(f\"  Per-trial range: [{logp_values.min():.2f}, {logp_values.max():.2f}]\")\n",
    "print(f\"  Mean per-trial: {logp_values.mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94154bc0",
   "metadata": {},
   "source": [
    "## Appendix: Key Design Patterns\n",
    "\n",
    "### Pattern 1: Function Composition\n",
    "\n",
    "The framework allows you to compose functions hierarchically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ad92967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Multi-level computation\n",
    "\n",
    "@annotate_function(\n",
    "    inputs=[\"param_a\", \"param_b\"],\n",
    "    outputs=[\"intermediate\"]\n",
    ")\n",
    "def compute_intermediate(data):\n",
    "    \"\"\"Compute a simple intermediate value: sum of two inputs.\"\"\"\n",
    "    return data[:, 0] + data[:, 1]\n",
    "\n",
    "\n",
    "@annotate_function(\n",
    "    inputs=[\"intermediate\", \"param_c\"],\n",
    "    outputs=[\"final\"],\n",
    "    computed={\"intermediate\": compute_intermediate},\n",
    ")\n",
    "def compute_final(data):\n",
    "    \"\"\"Produce a final value using the intermediate and a secondary parameter.\"\"\"\n",
    "    # Expect data[:, 0] == intermediate, data[:, 1] == param_c\n",
    "    return data[:, 0] * data[:, 1]\n",
    "\n",
    "print(\"Hierarchical function composition (metadata):\")\n",
    "print(f\"  Level 1: {compute_intermediate.inputs} -> {compute_intermediate.outputs}\")\n",
    "print(f\"  Level 2: {compute_final.inputs} -> {compute_final.outputs}\")\n",
    "print(f\"  Computed mapping on Level 2: {list(compute_final.computed.keys())}\")\n",
    "\n",
    "# Numeric example that explicitly shows compute_intermediate feeding compute_final\n",
    "base_data = np.array([[1.0, 2.0], [3.0, 4.0]])  # columns: param_a, param_b\n",
    "param_c = np.array([10.0, 20.0])                 # param_c for each row\n",
    "\n",
    "# 1) Compute intermediate explicitly\n",
    "intermediate_vals = compute_intermediate(base_data)\n",
    "print(\"\\nExplicit execution:\")\n",
    "print(f\"  base_data:\\n{base_data}\")\n",
    "print(f\"  intermediate (param_a + param_b): {intermediate_vals}\")\n",
    "\n",
    "# 2) Use intermediate together with param_c to compute final output\n",
    "final_input = np.column_stack([intermediate_vals, param_c])\n",
    "final_vals = compute_final(final_input)\n",
    "print(f\"  param_c: {param_c}\")\n",
    "print(f\"  final output (intermediate * param_c): {final_vals}\")\n",
    "\n",
    "# Note: when used inside the RL-SSM assembly (e.g. via make_rl_logp_func),\n",
    "# the framework will automatically call the `compute_intermediate` function\n",
    "# to produce the `intermediate` value and pass it into `compute_final` based\n",
    "# on the `computed` metadata shown above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0257f7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now reproduce the same workflow using the framework's make_rl_logp_func\n",
    "\n",
    "# Wrap the existing compute_intermediate as a function that outputs 'v'\n",
    "annotated_v = annotate_function(inputs=[\"param_a\", \"param_b\"], outputs=[\"v\"])(compute_intermediate)\n",
    "\n",
    "# Wrap compute_final as the 'SSM-like' function that consumes 'v' and 'param_c'\n",
    "ssm_wrapped = annotate_function(inputs=[\"v\", \"param_c\"], computed={\"v\": annotated_v})(compute_final)\n",
    "\n",
    "# Build a logp function: 1 subject, 2 trials (matches base_data)\n",
    "logp_fn_auto = make_rl_logp_func(\n",
    "    ssm_wrapped,\n",
    "    n_participants=1,\n",
    "    n_trials=2,\n",
    "    data_cols=[\"param_a\", \"param_b\"],\n",
    "    list_params=[\"param_c\"],\n",
    "    extra_fields=[],\n",
    ")\n",
    "\n",
    "# Use same inputs as manual example\n",
    "data_for_logp = base_data  # shape (2,2) with columns param_a,param_b\n",
    "\n",
    "# list_params are passed as separate arrays in the same order as `list_params`\n",
    "result_auto = logp_fn_auto(data_for_logp, param_c)\n",
    "\n",
    "print(\"Framework-driven execution:\")\n",
    "print(f\"  data_for_logp:\\n{data_for_logp}\")\n",
    "print(f\"  param_c: {param_c}\")\n",
    "print(f\"  result from make_rl_logp_func: {result_auto}\")\n",
    "\n",
    "# Compare to the manual final_vals computed previously\n",
    "print(f\"\\nManual final_vals: {final_vals}\")\n",
    "print(f\"Match? {np.allclose(result_auto, final_vals)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hssm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
